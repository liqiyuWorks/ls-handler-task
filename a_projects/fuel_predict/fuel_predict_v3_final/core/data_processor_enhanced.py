#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆæ•°æ®å¤„ç†å™¨ - ä¸“é—¨å¤„ç†NOONæŠ¥å‘Šæ•°æ®
Enhanced Data Processor for NOON Report Analysis

åŠŸèƒ½ï¼š
1. ç­›é€‰NOONæŠ¥å‘Šç±»å‹ä¸”èˆªè¡Œæ—¶é—´ä¸º24æˆ–25å°æ—¶çš„æ•°æ®
2. åŸºäºèˆªè¿è¡Œä¸šå±æ€§å’Œç§Ÿçº¦æ¡æ¬¾è¿›è¡Œç‰¹å¾å·¥ç¨‹
3. èˆ¹èˆ¶æ¡£æ¡ˆç‰¹å¾æå–å’Œå¤„ç†
4. æ•°æ®è´¨é‡æ§åˆ¶å’Œå¼‚å¸¸å€¼å¤„ç†

ä½œè€…: èˆ¹èˆ¶æ²¹è€—é¢„æµ‹ç³»ç»Ÿ
æ—¥æœŸ: 2025-09-21
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class EnhancedDataProcessor:
    """å¢å¼ºç‰ˆæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.ship_type_mapping = {
            'BULK CARRIER': 'Bulk Carrier',
            'Bulk Carrier': 'Bulk Carrier',
            'OPEN HATCH CARGO SHIP': 'Open Hatch Cargo',
            'CHEMICAL/PRODUCTS TANKER': 'Chemical Tanker',
            'Chemical/Products Tanker': 'Chemical Tanker',
            'GENERAL CARGO SHIP': 'General Cargo',
            'General Cargo Ship': 'General Cargo',
            'GENERAL CARGO SHIP (OPEN HATCH)': 'General Cargo',
            'CRUDE OIL TANKER': 'Crude Oil Tanker',
            'Crude Oil Tanker': 'Crude Oil Tanker',
            'PRODUCTS TANKER': 'Chemical Tanker',
            'CONTAINER SHIP': 'Container Ship',
            'Container Ship': 'Container Ship',
            'BULK/CAUSTIC SODA CARRIER (CABU)': 'Bulk Carrier',
            'HEAVY LOAD CARRIER': 'General Cargo',
            'OTHER': 'Other',
            'other': 'Other',
            'tanker': 'Chemical Tanker'
        }
        
        # èˆ¹èˆ¶ç±»å‹ç³»æ•° (åŸºäºèˆªè¿è¡Œä¸šç»éªŒ)
        self.ship_efficiency_factors = {
            'Bulk Carrier': 1.0,
            'Container Ship': 1.15,
            'Crude Oil Tanker': 0.95,
            'Chemical Tanker': 1.05,
            'General Cargo': 1.10,
            'Open Hatch Cargo': 1.08,
            'Other': 1.12
        }
        
        # è½½é‡çŠ¶æ€ç³»æ•°
        self.load_condition_factors = {
            'Laden': 1.0,
            'Ballast': 0.85,
            'None': 0.95
        }
    
    def load_and_filter_data(self, data_path: str) -> pd.DataFrame:
        """
        åŠ è½½å¹¶ç­›é€‰æ•°æ®
        åªä¿ç•™NOONæŠ¥å‘Šä¸”èˆªè¡Œæ—¶é—´ä¸º24æˆ–25å°æ—¶çš„æ•°æ®
        """
        print("ğŸ“Š æ­£åœ¨åŠ è½½å’Œç­›é€‰æ•°æ®...")
        
        # è¯»å–æ•°æ®
        df = pd.read_csv(data_path)
        print(f"åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}")
        
        # ç­›é€‰NOONæŠ¥å‘Š
        noon_data = df[df['æŠ¥å‘Šç±»å‹'] == 'NOON'].copy()
        print(f"NOONæŠ¥å‘Šæ•°æ®è¡Œæ•°: {len(noon_data)}")
        
        # ç­›é€‰24æˆ–25å°æ—¶èˆªè¡Œæ•°æ®
        filtered_data = noon_data[
            (noon_data['èˆªè¡Œæ—¶é—´(hrs)'] == 24) | 
            (noon_data['èˆªè¡Œæ—¶é—´(hrs)'] == 25)
        ].copy()
        print(f"ç­›é€‰åæ•°æ®è¡Œæ•°: {len(filtered_data)}")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        self._quality_check(filtered_data)
        
        return filtered_data
    
    def _quality_check(self, df: pd.DataFrame):
        """æ•°æ®è´¨é‡æ£€æŸ¥"""
        print("\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
        
        key_columns = ['é‡æ²¹IFO(mt)', 'å¹³å‡é€Ÿåº¦(kts)', 'èˆ¹èˆ¶è½½é‡(t)', 'èˆ¹èˆ¶ç±»å‹']
        for col in key_columns:
            missing = df[col].isna().sum()
            print(f"  {col}: {missing} ä¸ªç¼ºå¤±å€¼")
        
        # æ£€æŸ¥å¼‚å¸¸å€¼
        fuel_outliers = df[df['é‡æ²¹IFO(mt)'] > 100].shape[0]
        speed_outliers = df[df['å¹³å‡é€Ÿåº¦(kts)'] > 25].shape[0]
        print(f"  é‡æ²¹æ¶ˆè€—å¼‚å¸¸å€¼ (>100mt): {fuel_outliers}")
        print(f"  é€Ÿåº¦å¼‚å¸¸å€¼ (>25kts): {speed_outliers}")
    
    def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç‰¹å¾å·¥ç¨‹ - åŸºäºèˆªè¿è¡Œä¸šå±æ€§å’Œç§Ÿçº¦æ¡æ¬¾
        """
        print("\nâš™ï¸ è¿›è¡Œç‰¹å¾å·¥ç¨‹...")
        
        enhanced_df = df.copy()
        
        # 1. èˆ¹èˆ¶ç±»å‹æ ‡å‡†åŒ–
        enhanced_df['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–'] = enhanced_df['èˆ¹èˆ¶ç±»å‹'].map(
            self.ship_type_mapping
        ).fillna('Other')
        
        # 2. èˆ¹èˆ¶æ•ˆç‡ç³»æ•° (åŸºäºèˆ¹å‹)
        enhanced_df['èˆ¹èˆ¶æ•ˆç‡ç³»æ•°'] = enhanced_df['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–'].map(
            self.ship_efficiency_factors
        )
        
        # 3. è½½é‡çŠ¶æ€ç³»æ•°
        enhanced_df['è½½é‡çŠ¶æ€_å¡«å……'] = enhanced_df['è½½é‡çŠ¶æ€'].fillna('None')
        enhanced_df['è½½é‡çŠ¶æ€ç³»æ•°'] = enhanced_df['è½½é‡çŠ¶æ€_å¡«å……'].map(
            self.load_condition_factors
        )
        
        # 4. èˆ¹èˆ¶å°ºå¯¸ç‰¹å¾
        enhanced_df['è½½é‡å¨ä½ç­‰çº§'] = pd.cut(
            enhanced_df['èˆ¹èˆ¶è½½é‡(t)'], 
            bins=[0, 20000, 50000, 100000, 200000, float('inf')],
            labels=['å°å‹', 'ä¸­å‹', 'å¤§å‹', 'è¶…å¤§å‹', 'å·¨å‹']
        )
        
        # 5. èˆ¹é¾„åˆ†ç»„
        enhanced_df['èˆ¹é¾„_æ•°å€¼'] = pd.to_numeric(enhanced_df['èˆ¹é¾„'], errors='coerce')
        enhanced_df['èˆ¹é¾„åˆ†ç»„'] = pd.cut(
            enhanced_df['èˆ¹é¾„_æ•°å€¼'],
            bins=[0, 5, 10, 20, float('inf')],
            labels=['æ–°èˆ¹', 'ä¸­ç­‰èˆ¹é¾„', 'è€èˆ¹', 'é«˜é¾„èˆ¹']
        )
        
        # 6. é€Ÿåº¦æ•ˆç‡æŒ‡æ ‡
        enhanced_df['é€Ÿåº¦æ•ˆç‡'] = enhanced_df['èˆªè¡Œè·ç¦»(nm)'] / enhanced_df['èˆªè¡Œæ—¶é—´(hrs)']
        enhanced_df['ç†è®ºé€Ÿåº¦å·®å¼‚'] = enhanced_df['å¹³å‡é€Ÿåº¦(kts)'] - enhanced_df['é€Ÿåº¦æ•ˆç‡']
        
        # 7. ç§Ÿçº¦æ¡æ¬¾ç›¸å…³ç‰¹å¾ (åŸºäºCPæ¡æ¬¾)
        enhanced_df['é‡æ²¹CP_æ ‡å‡†åŒ–'] = enhanced_df['é‡æ²¹cp'].fillna(enhanced_df['é‡æ²¹cp'].median())
        enhanced_df['è½»æ²¹CP_æ ‡å‡†åŒ–'] = enhanced_df['è½»æ²¹cp'].fillna(enhanced_df['è½»æ²¹cp'].median())
        enhanced_df['èˆªé€ŸCP_æ ‡å‡†åŒ–'] = enhanced_df['èˆªé€Ÿcp'].fillna(enhanced_df['èˆªé€Ÿcp'].median())
        
        # 8. æ²¹è€—æ•ˆç‡æŒ‡æ ‡ (é˜²æ­¢é™¤é›¶é”™è¯¯)
        enhanced_df['å•ä½è·ç¦»æ²¹è€—'] = enhanced_df['é‡æ²¹IFO(mt)'] / np.maximum(enhanced_df['èˆªè¡Œè·ç¦»(nm)'], 0.1)
        enhanced_df['å•ä½æ—¶é—´æ²¹è€—'] = enhanced_df['é‡æ²¹IFO(mt)'] / np.maximum(enhanced_df['èˆªè¡Œæ—¶é—´(hrs)'], 0.1)
        enhanced_df['è½½é‡å¨æ²¹è€—æ¯”'] = enhanced_df['é‡æ²¹IFO(mt)'] / np.maximum(enhanced_df['èˆ¹èˆ¶è½½é‡(t)'], 1000) * 1000
        
        # 9. ç»¼åˆæ•ˆç‡æŒ‡æ ‡
        enhanced_df['ç»¼åˆæ•ˆç‡æŒ‡æ ‡'] = (
            enhanced_df['èˆ¹èˆ¶æ•ˆç‡ç³»æ•°'] * 
            enhanced_df['è½½é‡çŠ¶æ€ç³»æ•°'] * 
            enhanced_df['å¹³å‡é€Ÿåº¦(kts)'] / 10
        )
        
        # 10. åœ°ç†ä½ç½®ç‰¹å¾ (ä»ä½ç½®å­—ç¬¦ä¸²æå–)
        enhanced_df = self._extract_location_features(enhanced_df)
        
        print(f"ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæ–°å¢ç‰¹å¾æ•°: {len(enhanced_df.columns) - len(df.columns)}")
        
        return enhanced_df
    
    def _extract_location_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æå–åœ°ç†ä½ç½®ç‰¹å¾"""
        try:
            # è§£æä½ç½®åæ ‡
            location_data = df['ä½ç½®'].str.extract(r'\(([^,]+),\s*([^)]+)\)')
            df['çº¬åº¦'] = pd.to_numeric(location_data[0], errors='coerce')
            df['ç»åº¦'] = pd.to_numeric(location_data[1], errors='coerce')
            
            # åœ°ç†åŒºåŸŸåˆ†ç±»
            df['èˆªè¡ŒåŒºåŸŸ'] = 'Unknown'
            
            # æ ¹æ®ç»çº¬åº¦åˆ’åˆ†ä¸»è¦èˆªè¿åŒºåŸŸ
            conditions = [
                (df['çº¬åº¦'].between(-10, 30) & df['ç»åº¦'].between(30, 120)),  # å°åº¦æ´‹
                (df['çº¬åº¦'].between(0, 50) & df['ç»åº¦'].between(100, 180)),    # è¥¿å¤ªå¹³æ´‹
                (df['çº¬åº¦'].between(30, 70) & df['ç»åº¦'].between(-30, 50)),    # åŒ—å¤§è¥¿æ´‹
                (df['çº¬åº¦'].between(-40, 0) & df['ç»åº¦'].between(-70, 20)),    # å—å¤§è¥¿æ´‹
                (df['çº¬åº¦'].between(10, 50) & df['ç»åº¦'].between(80, 140)),    # ä¸œäºšæµ·åŸŸ
            ]
            
            choices = ['å°åº¦æ´‹', 'è¥¿å¤ªå¹³æ´‹', 'åŒ—å¤§è¥¿æ´‹', 'å—å¤§è¥¿æ´‹', 'ä¸œäºšæµ·åŸŸ']
            
            df['èˆªè¡ŒåŒºåŸŸ'] = np.select(conditions, choices, default='å…¶ä»–åŒºåŸŸ')
            
        except Exception as e:
            print(f"ä½ç½®ç‰¹å¾æå–å‡ºé”™: {e}")
            df['çº¬åº¦'] = 0
            df['ç»åº¦'] = 0
            df['èˆªè¡ŒåŒºåŸŸ'] = 'Unknown'
        
        return df
    
    def prepare_model_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
        """
        å‡†å¤‡ç”¨äºæ¨¡å‹è®­ç»ƒçš„æ•°æ®
        """
        print("\nğŸ“‹ å‡†å¤‡æ¨¡å‹è®­ç»ƒæ•°æ®...")
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [
            # åŸºç¡€ç‰¹å¾
            'å¹³å‡é€Ÿåº¦(kts)', 'èˆªè¡Œè·ç¦»(nm)', 'èˆªè¡Œæ—¶é—´(hrs)',
            'èˆ¹èˆ¶è½½é‡(t)', 'èˆ¹èˆ¶åƒæ°´(m)', 'èˆ¹èˆ¶æ€»é•¿åº¦(m)',
            
            # å·¥ç¨‹åŒ–ç‰¹å¾
            'èˆ¹èˆ¶æ•ˆç‡ç³»æ•°', 'è½½é‡çŠ¶æ€ç³»æ•°',
            'å•ä½è·ç¦»æ²¹è€—', 'å•ä½æ—¶é—´æ²¹è€—', 'è½½é‡å¨æ²¹è€—æ¯”',
            'ç»¼åˆæ•ˆç‡æŒ‡æ ‡', 'ç†è®ºé€Ÿåº¦å·®å¼‚',
            
            # ç§Ÿçº¦ç‰¹å¾
            'é‡æ²¹CP_æ ‡å‡†åŒ–', 'è½»æ²¹CP_æ ‡å‡†åŒ–', 'èˆªé€ŸCP_æ ‡å‡†åŒ–',
            
            # ä½ç½®ç‰¹å¾
            'çº¬åº¦', 'ç»åº¦'
        ]
        
        # åˆ†ç±»ç‰¹å¾ç¼–ç 
        categorical_features = ['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–', 'è½½é‡å¨ä½ç­‰çº§', 'èˆ¹é¾„åˆ†ç»„', 'è½½é‡çŠ¶æ€_å¡«å……', 'èˆªè¡ŒåŒºåŸŸ']
        
        model_df = df.copy()
        
        # å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œç¼–ç 
        for cat_feature in categorical_features:
            if cat_feature in model_df.columns:
                model_df[f'{cat_feature}_ç¼–ç '] = pd.Categorical(model_df[cat_feature]).codes
                feature_columns.append(f'{cat_feature}_ç¼–ç ')
        
        # å¤„ç†ç¼ºå¤±å€¼
        for col in feature_columns:
            if col in model_df.columns:
                if model_df[col].dtype in ['float64', 'int64']:
                    model_df[col] = model_df[col].fillna(model_df[col].median())
                else:
                    model_df[col] = model_df[col].fillna(0)
        
        # å¼‚å¸¸å€¼å¤„ç†
        model_df = self._handle_outliers(model_df)
        
        print(f"æ¨¡å‹ç‰¹å¾æ•°é‡: {len(feature_columns)}")
        print(f"è®­ç»ƒæ•°æ®è¡Œæ•°: {len(model_df)}")
        
        return model_df, feature_columns
    
    def _handle_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†å¼‚å¸¸å€¼"""
        # ä½¿ç”¨IQRæ–¹æ³•å¤„ç†é‡æ²¹æ¶ˆè€—å¼‚å¸¸å€¼
        Q1 = df['é‡æ²¹IFO(mt)'].quantile(0.25)
        Q3 = df['é‡æ²¹IFO(mt)'].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # é™åˆ¶å¼‚å¸¸å€¼
        df.loc[df['é‡æ²¹IFO(mt)'] < lower_bound, 'é‡æ²¹IFO(mt)'] = lower_bound
        df.loc[df['é‡æ²¹IFO(mt)'] > upper_bound, 'é‡æ²¹IFO(mt)'] = upper_bound
        
        return df
    
    def get_ship_speed_summary(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç”Ÿæˆèˆ¹èˆ¶-é€Ÿåº¦-æ²¹è€—æ±‡æ€»è¡¨
        ç”¨äº"XXèˆ¹èˆ¶åœ¨XXå¹³å‡é€Ÿåº¦ä¸‹çš„é‡æ²¹mté¢„æµ‹"
        """
        print("\nğŸ“ˆ ç”Ÿæˆèˆ¹èˆ¶-é€Ÿåº¦-æ²¹è€—æ±‡æ€»...")
        
        summary = df.groupby(['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–', 'å¹³å‡é€Ÿåº¦(kts)']).agg({
            'é‡æ²¹IFO(mt)': ['mean', 'std', 'count'],
            'èˆ¹èˆ¶è½½é‡(t)': 'mean',
            'è½½é‡çŠ¶æ€ç³»æ•°': 'mean',
            'ç»¼åˆæ•ˆç‡æŒ‡æ ‡': 'mean'
        }).round(2)
        
        # æ‰å¹³åŒ–åˆ—å
        summary.columns = [f'{col[0]}_{col[1]}' if col[1] else col[0] for col in summary.columns]
        summary = summary.reset_index()
        
        # åªä¿ç•™æœ‰è¶³å¤Ÿæ ·æœ¬çš„ç»„åˆ
        summary = summary[summary['é‡æ²¹IFO(mt)_count'] >= 5]
        
        print(f"èˆ¹èˆ¶-é€Ÿåº¦ç»„åˆæ•°: {len(summary)}")
        
        return summary

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®å¤„ç†æµç¨‹"""
    processor = EnhancedDataProcessor()
    
    # æ•°æ®è·¯å¾„
    data_path = "data/æ²¹è€—æ•°æ®ALLï¼ˆ0804ï¼‰.csv"
    
    try:
        # 1. åŠ è½½å’Œç­›é€‰æ•°æ®
        filtered_data = processor.load_and_filter_data(data_path)
        
        # 2. ç‰¹å¾å·¥ç¨‹
        enhanced_data = processor.engineer_features(filtered_data)
        
        # 3. å‡†å¤‡æ¨¡å‹æ•°æ®
        model_data, feature_columns = processor.prepare_model_data(enhanced_data)
        
        # 4. ç”Ÿæˆæ±‡æ€»è¡¨
        summary = processor.get_ship_speed_summary(enhanced_data)
        
        # 5. ä¿å­˜å¤„ç†åçš„æ•°æ®
        output_path = "data/processed_noon_data.csv"
        model_data.to_csv(output_path, index=False)
        print(f"\nâœ… å¤„ç†å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
        
        # ä¿å­˜æ±‡æ€»è¡¨
        summary_path = "data/ship_speed_summary.csv"
        summary.to_csv(summary_path, index=False)
        print(f"âœ… æ±‡æ€»è¡¨å·²ä¿å­˜åˆ°: {summary_path}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
        print(f"  - æ€»è¡Œæ•°: {len(model_data)}")
        print(f"  - ç‰¹å¾æ•°: {len(feature_columns)}")
        print(f"  - èˆ¹èˆ¶ç±»å‹: {enhanced_data['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–'].nunique()}")
        print(f"  - é€Ÿåº¦èŒƒå›´: {model_data['å¹³å‡é€Ÿåº¦(kts)'].min():.1f} - {model_data['å¹³å‡é€Ÿåº¦(kts)'].max():.1f} kts")
        print(f"  - æ²¹è€—èŒƒå›´: {model_data['é‡æ²¹IFO(mt)'].min():.1f} - {model_data['é‡æ²¹IFO(mt)'].max():.1f} mt")
        
        return model_data, feature_columns, summary
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å‡ºé”™: {e}")
        return None, None, None

if __name__ == "__main__":
    main()
