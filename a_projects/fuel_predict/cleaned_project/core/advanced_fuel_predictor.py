#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§èˆ¹èˆ¶æ²¹è€—é¢„æµ‹æ¨¡å‹
Advanced Ship Fuel Consumption Prediction Model

ä¸“é—¨é’ˆå¯¹"XXèˆ¹èˆ¶åœ¨XXå¹³å‡é€Ÿåº¦ä¸‹çš„é‡æ²¹mté¢„æµ‹"è¿›è¡Œä¼˜åŒ–
åŸºäºèˆªè¿è¡Œä¸šå±æ€§ã€ç§Ÿçº¦æ¡æ¬¾ã€èˆ¹èˆ¶æ¡£æ¡ˆç‰¹å¾å»ºç«‹çš„é«˜ç²¾åº¦é¢„æµ‹æ¨¡å‹

ç‰¹è‰²åŠŸèƒ½ï¼š
1. å¤šç®—æ³•é›†æˆé¢„æµ‹ (Random Forest, XGBoost, LightGBM)
2. èˆ¹èˆ¶ç±»å‹ä¸“ç”¨æ¨¡å‹
3. é€Ÿåº¦åŒºé—´è‡ªé€‚åº”é¢„æµ‹
4. ç§Ÿçº¦æ¡æ¬¾æ™ºèƒ½åˆ†æ
5. å®æ—¶é¢„æµ‹API

ä½œè€…: èˆ¹èˆ¶æ²¹è€—é¢„æµ‹ç³»ç»Ÿ
æ—¥æœŸ: 2025-09-21
"""

import pandas as pd
import numpy as np
import joblib
import warnings
from typing import Dict, List, Tuple, Optional, Any
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os

# å°è¯•å¯¼å…¥é«˜çº§ç®—æ³•åº“
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

warnings.filterwarnings('ignore')

class AdvancedFuelPredictor:
    """é«˜çº§èˆ¹èˆ¶æ²¹è€—é¢„æµ‹å™¨"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_columns = []
        self.ship_type_models = {}
        self.is_trained = False
        
        # èˆ¹èˆ¶ç±»å‹ç‰¹å®šå‚æ•°
        self.ship_type_params = {
            'Bulk Carrier': {'base_consumption': 22.5, 'speed_factor': 1.2},
            'Container Ship': {'base_consumption': 28.0, 'speed_factor': 1.4},
            'Crude Oil Tanker': {'base_consumption': 25.8, 'speed_factor': 1.1},
            'Chemical Tanker': {'base_consumption': 24.2, 'speed_factor': 1.15},
            'General Cargo': {'base_consumption': 23.5, 'speed_factor': 1.25},
            'Open Hatch Cargo': {'base_consumption': 24.8, 'speed_factor': 1.18},
            'Other': {'base_consumption': 25.0, 'speed_factor': 1.2}
        }
        
        # é€Ÿåº¦åŒºé—´å‚æ•°
        self.speed_ranges = {
            'low': (0, 8),      # ä½é€Ÿ
            'medium': (8, 15),  # ä¸­é€Ÿ
            'high': (15, 25)    # é«˜é€Ÿ
        }
    
    def load_processed_data(self, data_path: str) -> pd.DataFrame:
        """åŠ è½½å¤„ç†åçš„æ•°æ®"""
        print("ğŸ“‚ åŠ è½½å¤„ç†åçš„æ•°æ®...")
        df = pd.read_csv(data_path)
        print(f"æ•°æ®è¡Œæ•°: {len(df)}")
        return df
    
    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ“‹ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # ç‰¹å¾åˆ—
        feature_columns = [
            # åŸºç¡€èˆ¹èˆ¶ç‰¹å¾
            'å¹³å‡é€Ÿåº¦(kts)', 'èˆªè¡Œè·ç¦»(nm)', 'èˆªè¡Œæ—¶é—´(hrs)',
            'èˆ¹èˆ¶è½½é‡(t)', 'èˆ¹èˆ¶åƒæ°´(m)', 'èˆ¹èˆ¶æ€»é•¿åº¦(m)',
            
            # å·¥ç¨‹åŒ–ç‰¹å¾
            'èˆ¹èˆ¶æ•ˆç‡ç³»æ•°', 'è½½é‡çŠ¶æ€ç³»æ•°',
            'å•ä½è·ç¦»æ²¹è€—', 'å•ä½æ—¶é—´æ²¹è€—', 'è½½é‡å¨æ²¹è€—æ¯”',
            'ç»¼åˆæ•ˆç‡æŒ‡æ ‡', 'ç†è®ºé€Ÿåº¦å·®å¼‚',
            
            # ç§Ÿçº¦ç‰¹å¾
            'é‡æ²¹CP_æ ‡å‡†åŒ–', 'è½»æ²¹CP_æ ‡å‡†åŒ–', 'èˆªé€ŸCP_æ ‡å‡†åŒ–',
            
            # ä½ç½®ç‰¹å¾
            'çº¬åº¦', 'ç»åº¦',
            
            # åˆ†ç±»ç‰¹å¾ç¼–ç 
            'èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–_ç¼–ç ', 'è½½é‡å¨ä½ç­‰çº§_ç¼–ç ', 
            'èˆ¹é¾„åˆ†ç»„_ç¼–ç ', 'è½½é‡çŠ¶æ€_å¡«å……_ç¼–ç ', 'èˆªè¡ŒåŒºåŸŸ_ç¼–ç '
        ]
        
        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å­˜åœ¨
        available_features = [col for col in feature_columns if col in df.columns]
        missing_features = [col for col in feature_columns if col not in df.columns]
        
        if missing_features:
            print(f"âš ï¸ ç¼ºå¤±ç‰¹å¾: {missing_features}")
        
        self.feature_columns = available_features
        
        # å‡†å¤‡ç‰¹å¾çŸ©é˜µ
        X = df[self.feature_columns].values
        y = df['é‡æ²¹IFO(mt)'].values
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        
        # è¿›ä¸€æ­¥æ¸…ç†å¼‚å¸¸å€¼
        X = np.clip(X, -1e6, 1e6)  # é™åˆ¶æ•°å€¼èŒƒå›´
        
        print(f"ç‰¹å¾æ•°é‡: {len(self.feature_columns)}")
        print(f"æ ·æœ¬æ•°é‡: {len(X)}")
        
        return X, y, self.feature_columns
    
    def train_ensemble_models(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """è®­ç»ƒé›†æˆæ¨¡å‹"""
        print("\nğŸ¤– è®­ç»ƒé›†æˆé¢„æµ‹æ¨¡å‹...")
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        self.scalers['main'] = scaler
        
        models = {}
        results = {}
        
        # 1. Random Forest
        print("  è®­ç»ƒ Random Forest...")
        rf_params = {
            'n_estimators': 200,
            'max_depth': 15,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'random_state': 42,
            'n_jobs': -1
        }
        
        rf_model = RandomForestRegressor(**rf_params)
        rf_model.fit(X_train, y_train)
        rf_pred = rf_model.predict(X_test)
        
        models['random_forest'] = rf_model
        results['random_forest'] = self._evaluate_model(y_test, rf_pred)
        
        # 2. XGBoost (å¦‚æœå¯ç”¨)
        if XGBOOST_AVAILABLE:
            print("  è®­ç»ƒ XGBoost...")
            xgb_params = {
                'n_estimators': 200,
                'max_depth': 8,
                'learning_rate': 0.1,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42,
                'n_jobs': -1
            }
            
            xgb_model = xgb.XGBRegressor(**xgb_params)
            xgb_model.fit(X_train_scaled, y_train)
            xgb_pred = xgb_model.predict(X_test_scaled)
            
            models['xgboost'] = xgb_model
            results['xgboost'] = self._evaluate_model(y_test, xgb_pred)
        
        # 3. LightGBM (å¦‚æœå¯ç”¨)
        if LIGHTGBM_AVAILABLE:
            print("  è®­ç»ƒ LightGBM...")
            lgb_params = {
                'n_estimators': 200,
                'max_depth': 8,
                'learning_rate': 0.1,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42,
                'n_jobs': -1,
                'verbose': -1
            }
            
            lgb_model = lgb.LGBMRegressor(**lgb_params)
            lgb_model.fit(X_train_scaled, y_train)
            lgb_pred = lgb_model.predict(X_test_scaled)
            
            models['lightgbm'] = lgb_model
            results['lightgbm'] = self._evaluate_model(y_test, lgb_pred)
        
        # é›†æˆé¢„æµ‹
        ensemble_pred = self._ensemble_predict(models, X_test, X_test_scaled)
        results['ensemble'] = self._evaluate_model(y_test, ensemble_pred)
        
        self.models = models
        
        # æ˜¾ç¤ºç»“æœ
        self._display_results(results)
        
        return results
    
    def _evaluate_model(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        mae = mean_absolute_error(y_true, y_pred)
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_true, y_pred)
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
        
        return {
            'MAE': mae,
            'MSE': mse,
            'RMSE': rmse,
            'R2': r2,
            'MAPE': mape
        }
    
    def _ensemble_predict(self, models: Dict, X: np.ndarray, X_scaled: np.ndarray) -> np.ndarray:
        """é›†æˆé¢„æµ‹"""
        predictions = []
        weights = []
        
        # Random Forest
        if 'random_forest' in models:
            pred = models['random_forest'].predict(X)
            predictions.append(pred)
            weights.append(0.4)  # RFæƒé‡
        
        # XGBoost
        if 'xgboost' in models:
            pred = models['xgboost'].predict(X_scaled)
            predictions.append(pred)
            weights.append(0.35)  # XGBæƒé‡
        
        # LightGBM
        if 'lightgbm' in models:
            pred = models['lightgbm'].predict(X_scaled)
            predictions.append(pred)
            weights.append(0.25)  # LGBæƒé‡
        
        # åŠ æƒå¹³å‡
        if len(predictions) > 1:
            # å½’ä¸€åŒ–æƒé‡
            weights = np.array(weights[:len(predictions)])
            weights = weights / weights.sum()
            
            ensemble_pred = np.average(predictions, axis=0, weights=weights)
        else:
            ensemble_pred = predictions[0]
        
        return ensemble_pred
    
    def _display_results(self, results: Dict):
        """æ˜¾ç¤ºè®­ç»ƒç»“æœ"""
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
        print("-" * 70)
        print(f"{'æ¨¡å‹':<15} {'MAE':<8} {'RMSE':<8} {'RÂ²':<8} {'MAPE(%)':<10}")
        print("-" * 70)
        
        for model_name, metrics in results.items():
            print(f"{model_name:<15} {metrics['MAE']:<8.2f} {metrics['RMSE']:<8.2f} "
                  f"{metrics['R2']:<8.3f} {metrics['MAPE']:<10.2f}")
        
        print("-" * 70)
    
    def train_ship_specific_models(self, df: pd.DataFrame):
        """è®­ç»ƒèˆ¹èˆ¶ç±»å‹ä¸“ç”¨æ¨¡å‹"""
        print("\nğŸš¢ è®­ç»ƒèˆ¹èˆ¶ç±»å‹ä¸“ç”¨æ¨¡å‹...")
        
        ship_types = df['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–'].unique()
        
        for ship_type in ship_types:
            if pd.isna(ship_type):
                continue
                
            ship_data = df[df['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–'] == ship_type]
            
            if len(ship_data) < 100:  # æ ·æœ¬å¤ªå°‘è·³è¿‡
                continue
            
            print(f"  è®­ç»ƒ {ship_type} ä¸“ç”¨æ¨¡å‹ (æ ·æœ¬æ•°: {len(ship_data)})")
            
            # å‡†å¤‡æ•°æ®
            X_ship = ship_data[self.feature_columns].values
            y_ship = ship_data['é‡æ²¹IFO(mt)'].values
            
            X_ship = np.nan_to_num(X_ship, nan=0.0)
            
            if len(X_ship) > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ ·æœ¬
                # è®­ç»ƒç®€åŒ–çš„Random Forestæ¨¡å‹
                model = RandomForestRegressor(
                    n_estimators=100,
                    max_depth=10,
                    random_state=42,
                    n_jobs=-1
                )
                model.fit(X_ship, y_ship)
                self.ship_type_models[ship_type] = model
        
        print(f"å®Œæˆ {len(self.ship_type_models)} ä¸ªèˆ¹èˆ¶ä¸“ç”¨æ¨¡å‹è®­ç»ƒ")
    
    def predict_fuel_consumption(self, ship_type: str, speed: float, 
                               dwt: float = None, load_condition: str = 'Laden',
                               **kwargs) -> Dict:
        """
        é¢„æµ‹èˆ¹èˆ¶æ²¹è€—
        
        Args:
            ship_type: èˆ¹èˆ¶ç±»å‹
            speed: å¹³å‡é€Ÿåº¦ (kts)
            dwt: è½½é‡å¨ (å¯é€‰)
            load_condition: è½½é‡çŠ¶æ€
            **kwargs: å…¶ä»–ç‰¹å¾å‚æ•°
        
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        try:
            # æ„å»ºç‰¹å¾å‘é‡
            features = self._build_feature_vector(
                ship_type, speed, dwt, load_condition, **kwargs
            )
            
            # é›†æˆé¢„æµ‹
            ensemble_pred = self._predict_with_ensemble(features)
            
            # èˆ¹èˆ¶ä¸“ç”¨æ¨¡å‹é¢„æµ‹
            ship_specific_pred = self._predict_with_ship_model(
                ship_type, features
            )
            
            # åŸºäºè§„åˆ™çš„é¢„æµ‹ (ä½œä¸ºå¤‡é€‰)
            rule_based_pred = self._predict_with_rules(
                ship_type, speed, dwt, load_condition
            )
            
            # ç»¼åˆé¢„æµ‹ (åŠ æƒå¹³å‡)
            if ship_specific_pred is not None:
                final_pred = 0.6 * ensemble_pred + 0.4 * ship_specific_pred
                confidence = 'High'
            else:
                final_pred = 0.8 * ensemble_pred + 0.2 * rule_based_pred
                confidence = 'Medium'
            
            # åˆç†æ€§æ£€æŸ¥
            final_pred = max(5.0, min(100.0, final_pred))
            
            return {
                'predicted_consumption': round(final_pred, 2),
                'confidence': confidence,
                'ship_type': ship_type,
                'speed': speed,
                'ensemble_prediction': round(ensemble_pred, 2),
                'ship_specific_prediction': round(ship_specific_pred, 2) if ship_specific_pred else None,
                'rule_based_prediction': round(rule_based_pred, 2),
                'prediction_range': (
                    round(final_pred * 0.9, 2),
                    round(final_pred * 1.1, 2)
                )
            }
            
        except Exception as e:
            print(f"é¢„æµ‹å‡ºé”™: {e}")
            # è¿”å›åŸºäºè§„åˆ™çš„é¢„æµ‹ä½œä¸ºå¤‡é€‰
            rule_pred = self._predict_with_rules(ship_type, speed, dwt, load_condition)
            return {
                'predicted_consumption': round(rule_pred, 2),
                'confidence': 'Low',
                'ship_type': ship_type,
                'speed': speed,
                'error': str(e)
            }
    
    def _build_feature_vector(self, ship_type: str, speed: float, 
                            dwt: float, load_condition: str, **kwargs) -> np.ndarray:
        """æ„å»ºç‰¹å¾å‘é‡"""
        # é»˜è®¤å€¼
        defaults = {
            'èˆªè¡Œè·ç¦»(nm)': speed * 24,  # å‡è®¾24å°æ—¶èˆªè¡Œ
            'èˆªè¡Œæ—¶é—´(hrs)': 24.0,
            'èˆ¹èˆ¶è½½é‡(t)': dwt or 50000,
            'èˆ¹èˆ¶åƒæ°´(m)': 8.0,
            'èˆ¹èˆ¶æ€»é•¿åº¦(m)': 150.0,
            'çº¬åº¦': 0.0,
            'ç»åº¦': 100.0
        }
        
        # æ›´æ–°é»˜è®¤å€¼
        defaults.update(kwargs)
        
        # æ„å»ºç‰¹å¾å‘é‡
        features = np.zeros(len(self.feature_columns))
        
        for i, col in enumerate(self.feature_columns):
            if col == 'å¹³å‡é€Ÿåº¦(kts)':
                features[i] = speed
            elif col in defaults:
                features[i] = defaults[col]
            elif col.endswith('_ç¼–ç '):
                # å¤„ç†ç¼–ç ç‰¹å¾
                features[i] = self._get_encoded_value(col, ship_type, load_condition)
            else:
                # è®¡ç®—å·¥ç¨‹ç‰¹å¾
                features[i] = self._calculate_engineered_feature(
                    col, ship_type, speed, defaults
                )
        
        return features.reshape(1, -1)
    
    def _get_encoded_value(self, col: str, ship_type: str, load_condition: str) -> float:
        """è·å–ç¼–ç å€¼"""
        if 'èˆ¹èˆ¶ç±»å‹' in col:
            type_mapping = {
                'Bulk Carrier': 0, 'Container Ship': 1, 'Crude Oil Tanker': 2,
                'Chemical Tanker': 3, 'General Cargo': 4, 'Open Hatch Cargo': 5, 'Other': 6
            }
            return type_mapping.get(ship_type, 6)
        elif 'è½½é‡çŠ¶æ€' in col:
            condition_mapping = {'Laden': 0, 'Ballast': 1, 'None': 2}
            return condition_mapping.get(load_condition, 2)
        else:
            return 0.0
    
    def _calculate_engineered_feature(self, col: str, ship_type: str, 
                                    speed: float, defaults: Dict) -> float:
        """è®¡ç®—å·¥ç¨‹ç‰¹å¾"""
        if col == 'èˆ¹èˆ¶æ•ˆç‡ç³»æ•°':
            efficiency_factors = {
                'Bulk Carrier': 1.0, 'Container Ship': 1.15, 'Crude Oil Tanker': 0.95,
                'Chemical Tanker': 1.05, 'General Cargo': 1.10, 'Open Hatch Cargo': 1.08, 'Other': 1.12
            }
            return efficiency_factors.get(ship_type, 1.0)
        elif col == 'è½½é‡çŠ¶æ€ç³»æ•°':
            return 1.0  # é»˜è®¤æ»¡è½½çŠ¶æ€
        elif col == 'å•ä½è·ç¦»æ²¹è€—':
            return 25.0 / defaults.get('èˆªè¡Œè·ç¦»(nm)', 240)
        elif col == 'å•ä½æ—¶é—´æ²¹è€—':
            return 25.0 / 24.0
        elif col == 'è½½é‡å¨æ²¹è€—æ¯”':
            return 25.0 / defaults.get('èˆ¹èˆ¶è½½é‡(t)', 50000) * 1000
        elif col == 'ç»¼åˆæ•ˆç‡æŒ‡æ ‡':
            return 1.0 * 1.0 * speed / 10
        elif col == 'ç†è®ºé€Ÿåº¦å·®å¼‚':
            return speed - speed  # 0å·®å¼‚
        else:
            return defaults.get(col.replace('CP_æ ‡å‡†åŒ–', 'cp'), 0.0)
    
    def _predict_with_ensemble(self, features: np.ndarray) -> float:
        """ä½¿ç”¨é›†æˆæ¨¡å‹é¢„æµ‹"""
        if not self.models:
            return 25.0  # é»˜è®¤å€¼
        
        predictions = []
        weights = []
        
        # Random Forest
        if 'random_forest' in self.models:
            pred = self.models['random_forest'].predict(features)[0]
            predictions.append(pred)
            weights.append(0.4)
        
        # XGBoost
        if 'xgboost' in self.models and 'main' in self.scalers:
            features_scaled = self.scalers['main'].transform(features)
            pred = self.models['xgboost'].predict(features_scaled)[0]
            predictions.append(pred)
            weights.append(0.35)
        
        # LightGBM
        if 'lightgbm' in self.models and 'main' in self.scalers:
            features_scaled = self.scalers['main'].transform(features)
            pred = self.models['lightgbm'].predict(features_scaled)[0]
            predictions.append(pred)
            weights.append(0.25)
        
        if predictions:
            weights = np.array(weights[:len(predictions)])
            weights = weights / weights.sum()
            return np.average(predictions, weights=weights)
        else:
            return 25.0
    
    def _predict_with_ship_model(self, ship_type: str, features: np.ndarray) -> Optional[float]:
        """ä½¿ç”¨èˆ¹èˆ¶ä¸“ç”¨æ¨¡å‹é¢„æµ‹"""
        if ship_type in self.ship_type_models:
            return self.ship_type_models[ship_type].predict(features)[0]
        return None
    
    def _predict_with_rules(self, ship_type: str, speed: float, 
                          dwt: float, load_condition: str) -> float:
        """åŸºäºè§„åˆ™çš„é¢„æµ‹"""
        params = self.ship_type_params.get(ship_type, self.ship_type_params['Other'])
        
        base_consumption = params['base_consumption']
        speed_factor = params['speed_factor']
        
        # é€Ÿåº¦å½±å“
        speed_effect = (speed / 12) ** speed_factor
        
        # è½½é‡å½±å“
        if dwt:
            dwt_effect = (dwt / 50000) ** 0.3
        else:
            dwt_effect = 1.0
        
        # è½½é‡çŠ¶æ€å½±å“
        load_effect = 1.0 if load_condition == 'Laden' else 0.85
        
        predicted_consumption = base_consumption * speed_effect * dwt_effect * load_effect
        
        return predicted_consumption
    
    def save_models(self, model_dir: str = "models"):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜ä¸»è¦æ¨¡å‹
        model_path = os.path.join(model_dir, f"advanced_fuel_models_{timestamp}.pkl")
        model_data = {
            'models': self.models,
            'scalers': self.scalers,
            'feature_columns': self.feature_columns,
            'ship_type_models': self.ship_type_models,
            'ship_type_params': self.ship_type_params,
            'is_trained': True
        }
        
        joblib.dump(model_data, model_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        return model_path
    
    def load_models(self, model_path: str) -> bool:
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            model_data = joblib.load(model_path)
            
            self.models = model_data['models']
            self.scalers = model_data['scalers']
            self.feature_columns = model_data['feature_columns']
            self.ship_type_models = model_data['ship_type_models']
            self.ship_type_params = model_data.get('ship_type_params', self.ship_type_params)
            self.is_trained = model_data.get('is_trained', True)
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def generate_prediction_report(self, ship_type: str, speed_range: Tuple[float, float],
                                 dwt: float = None) -> pd.DataFrame:
        """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š"""
        print(f"\nğŸ“‹ ç”Ÿæˆ {ship_type} é¢„æµ‹æŠ¥å‘Š...")
        
        speeds = np.arange(speed_range[0], speed_range[1] + 0.5, 0.5)
        results = []
        
        for speed in speeds:
            pred_result = self.predict_fuel_consumption(
                ship_type=ship_type,
                speed=speed,
                dwt=dwt,
                load_condition='Laden'
            )
            
            results.append({
                'èˆ¹èˆ¶ç±»å‹': ship_type,
                'é€Ÿåº¦(kts)': speed,
                'é¢„æµ‹æ²¹è€—(mt)': pred_result['predicted_consumption'],
                'ç½®ä¿¡åº¦': pred_result['confidence'],
                'é¢„æµ‹èŒƒå›´_ä¸‹é™': pred_result['prediction_range'][0],
                'é¢„æµ‹èŒƒå›´_ä¸Šé™': pred_result['prediction_range'][1]
            })
        
        report_df = pd.DataFrame(results)
        return report_df

def main():
    """ä¸»å‡½æ•° - è®­ç»ƒå’Œæµ‹è¯•é«˜çº§é¢„æµ‹æ¨¡å‹"""
    print("ğŸš€ å¯åŠ¨é«˜çº§èˆ¹èˆ¶æ²¹è€—é¢„æµ‹æ¨¡å‹è®­ç»ƒ...")
    
    predictor = AdvancedFuelPredictor()
    
    try:
        # 1. åŠ è½½å¤„ç†åçš„æ•°æ®
        df = predictor.load_processed_data("data/processed_noon_data.csv")
        
        # 2. å‡†å¤‡è®­ç»ƒæ•°æ®
        X, y, feature_columns = predictor.prepare_training_data(df)
        
        # 3. è®­ç»ƒé›†æˆæ¨¡å‹
        results = predictor.train_ensemble_models(X, y)
        
        # 4. è®­ç»ƒèˆ¹èˆ¶ä¸“ç”¨æ¨¡å‹
        predictor.train_ship_specific_models(df)
        
        # 5. ä¿å­˜æ¨¡å‹
        model_path = predictor.save_models()
        
        # 6. æµ‹è¯•é¢„æµ‹åŠŸèƒ½
        print("\nğŸ§ª æµ‹è¯•é¢„æµ‹åŠŸèƒ½...")
        
        test_cases = [
            {'ship_type': 'Bulk Carrier', 'speed': 12.0, 'dwt': 75000},
            {'ship_type': 'Container Ship', 'speed': 18.0, 'dwt': 120000},
            {'ship_type': 'Crude Oil Tanker', 'speed': 14.0, 'dwt': 200000}
        ]
        
        for case in test_cases:
            result = predictor.predict_fuel_consumption(**case)
            print(f"  {case['ship_type']} @ {case['speed']}kts: "
                  f"{result['predicted_consumption']}mt (ç½®ä¿¡åº¦: {result['confidence']})")
        
        # 7. ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
        report = predictor.generate_prediction_report(
            ship_type='Bulk Carrier',
            speed_range=(8, 20),
            dwt=75000
        )
        
        report_path = "outputs/bulk_carrier_prediction_report.csv"
        report.to_csv(report_path, index=False)
        print(f"\nâœ… é¢„æµ‹æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        print(f"\nğŸ‰ é«˜çº§é¢„æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“Š æœ€ä½³æ¨¡å‹æ€§èƒ½: RÂ² = {max([r['R2'] for r in results.values()]):.3f}")
        
        return predictor
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
