#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆèˆ¹èˆ¶æ²¹è€—é¢„æµ‹æ¨¡å‹ V3.0
Enhanced Ship Fuel Consumption Prediction Model V3.0

åŸºäºç›¸å…³æ€§åˆ†æä¼˜åŒ–çš„é¢„æµ‹æ¨¡å‹ï¼Œæ”¯æŒæ›´å¤šè¾“å…¥æ¡ä»¶ï¼š
- èˆ¹èˆ¶ç±»å‹ (ship_type)
- èˆªè¡Œé€Ÿåº¦ (speed) 
- è½½é‡å¨ (dwt)
- èˆ¹é¾„ (ship_age)
- è½½é‡çŠ¶æ€ (load_condition)
- èˆ¹èˆ¶å°ºå¯¸ (draft, length)
- åœ°ç†ä½ç½® (latitude, longitude)
- ç§Ÿçº¦æ¡æ¬¾ (charter_party_terms)

ä½œè€…: èˆ¹èˆ¶æ²¹è€—é¢„æµ‹ç³»ç»Ÿ
æ—¥æœŸ: 2025-09-21
ç‰ˆæœ¬: 3.0
"""

import pandas as pd
import numpy as np
import joblib
import warnings
from typing import Dict, List, Tuple, Optional, Any
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os

# å°è¯•å¯¼å…¥é«˜çº§ç®—æ³•åº“
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

warnings.filterwarnings('ignore')

class EnhancedFuelPredictorV3:
    """å¢å¼ºç‰ˆèˆ¹èˆ¶æ²¹è€—é¢„æµ‹å™¨ V3.0"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_selector = None
        self.selected_features = []
        self.feature_importance = {}
        self.is_trained = False
        
        # åŸºäºç›¸å…³æ€§åˆ†æçš„ç‰¹å¾é‡è¦æ€§æƒé‡
        self.feature_weights = {
            'é‡æ²¹CP_æ ‡å‡†åŒ–': 0.7003,
            'èˆ¹èˆ¶æ€»é•¿åº¦(m)': 0.5594,
            'èˆ¹èˆ¶è½½é‡(t)': 0.5586,
            'èˆªé€ŸCP_æ ‡å‡†åŒ–': 0.3020,
            'å¹³å‡é€Ÿåº¦(kts)': 0.2700,
            'èˆªè¡Œè·ç¦»(nm)': 0.2669,
            'è½»æ²¹CP_æ ‡å‡†åŒ–': 0.2496,
            'ç»¼åˆæ•ˆç‡æŒ‡æ ‡': 0.2449,
            'èˆ¹èˆ¶åƒæ°´(m)': 0.2388,
            'èˆ¹èˆ¶æ•ˆç‡ç³»æ•°': 0.1585,
            'çº¬åº¦': 0.1406,
            'ç»åº¦': 0.0413,
            'è½½é‡çŠ¶æ€ç³»æ•°': 0.0326,
            'èˆªè¡Œæ—¶é—´(hrs)': 0.0284,
            'èˆ¹é¾„_æ•°å€¼': 0.0119
        }
        
        # èˆ¹èˆ¶ç±»å‹æ˜ å°„å’Œå‚æ•°
        self.ship_type_mapping = {
            'bulk carrier': 'Bulk Carrier',
            'bulk': 'Bulk Carrier',
            'container ship': 'Container Ship',
            'container': 'Container Ship',
            'crude oil tanker': 'Crude Oil Tanker',
            'crude tanker': 'Crude Oil Tanker',
            'oil tanker': 'Crude Oil Tanker',
            'chemical tanker': 'Chemical Tanker',
            'product tanker': 'Chemical Tanker',
            'general cargo': 'General Cargo',
            'cargo ship': 'General Cargo',
            'open hatch': 'Open Hatch Cargo',
            'open hatch cargo': 'Open Hatch Cargo'
        }
        
        # åŸºäºåˆ†æç»“æœçš„èˆ¹èˆ¶ç±»å‹æ²¹è€—åŸºå‡†
        self.ship_type_baselines = {
            'Container Ship': 13.28,
            'General Cargo': 16.74,
            'Chemical Tanker': 18.41,
            'Other': 18.56,
            'Bulk Carrier': 23.31,
            'Open Hatch Cargo': 25.20,
            'Crude Oil Tanker': 27.85
        }
        
        # è½½é‡çŠ¶æ€å½±å“ç³»æ•°
        self.load_condition_factors = {
            'Laden': 1.0,      # æ»¡è½½
            'Ballast': 0.986,  # å‹è½½ (22.83/23.16)
            'None': 0.99
        }
        
        # èˆ¹é¾„å½±å“ç³»æ•° (åŸºäºåˆ†æç»“æœ)
        self.ship_age_factors = {
            'æ–°èˆ¹': 0.967,      # 22.40/23.16
            'ä¸­ç­‰èˆ¹é¾„': 1.007,   # 23.33/23.16
            'è€èˆ¹': 0.996,      # 23.06/23.16
            'é«˜é¾„èˆ¹': 0.993     # 22.98/23.16
        }
        
        # è½½é‡å¨ä½ç­‰çº§å½±å“ç³»æ•°
        self.dwt_class_factors = {
            'å°å‹': 0.590,      # 13.67/23.16
            'ä¸­å‹': 0.825,      # 19.11/23.16
            'å¤§å‹': 1.026,      # 23.77/23.16
            'è¶…å¤§å‹': 1.336,    # 30.94/23.16
            'å·¨å‹': 1.450       # 33.59/23.16
        }
    
    def load_and_prepare_data(self, data_path: str) -> pd.DataFrame:
        """åŠ è½½å’Œå‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")
        df = pd.read_csv(data_path)
        print(f"æ•°æ®è¡Œæ•°: {len(df)}")
        
        # åŸºäºç›¸å…³æ€§é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾
        self.selected_features = self._select_important_features(df)
        
        return df
    
    def _select_important_features(self, df: pd.DataFrame) -> List[str]:
        """åŸºäºç›¸å…³æ€§å’Œé‡è¦æ€§é€‰æ‹©ç‰¹å¾"""
        print("\nğŸ” åŸºäºç›¸å…³æ€§é€‰æ‹©é‡è¦ç‰¹å¾...")
        
        # é«˜ç›¸å…³æ€§ç‰¹å¾ (>0.2)
        high_corr_features = [
            'å¹³å‡é€Ÿåº¦(kts)', 'èˆªè¡Œè·ç¦»(nm)', 'èˆ¹èˆ¶è½½é‡(t)', 
            'èˆ¹èˆ¶åƒæ°´(m)', 'èˆ¹èˆ¶æ€»é•¿åº¦(m)', 'èˆ¹é¾„_æ•°å€¼',
            'èˆ¹èˆ¶æ•ˆç‡ç³»æ•°', 'è½½é‡çŠ¶æ€ç³»æ•°', 'ç»¼åˆæ•ˆç‡æŒ‡æ ‡',
            'é‡æ²¹CP_æ ‡å‡†åŒ–', 'è½»æ²¹CP_æ ‡å‡†åŒ–', 'èˆªé€ŸCP_æ ‡å‡†åŒ–',
            'çº¬åº¦', 'ç»åº¦'
        ]
        
        # é‡è¦åˆ†ç±»ç‰¹å¾ç¼–ç 
        categorical_features = [
            'èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–_ç¼–ç ', 'è½½é‡å¨ä½ç­‰çº§_ç¼–ç ', 
            'èˆ¹é¾„åˆ†ç»„_ç¼–ç ', 'è½½é‡çŠ¶æ€_å¡«å……_ç¼–ç ', 'èˆªè¡ŒåŒºåŸŸ_ç¼–ç '
        ]
        
        # åˆå¹¶æ‰€æœ‰é‡è¦ç‰¹å¾
        selected_features = []
        for feature in high_corr_features + categorical_features:
            if feature in df.columns:
                selected_features.append(feature)
        
        print(f"é€‰æ‹©çš„ç‰¹å¾æ•°é‡: {len(selected_features)}")
        print("ä¸»è¦ç‰¹å¾:", selected_features[:10])
        
        return selected_features
    
    def train_optimized_model(self, df: pd.DataFrame) -> Dict:
        """è®­ç»ƒä¼˜åŒ–åçš„æ¨¡å‹"""
        print("\nğŸ¤– è®­ç»ƒä¼˜åŒ–æ¨¡å‹...")
        
        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
        X = df[self.selected_features].values
        y = df['é‡æ²¹IFO(mt)'].values
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        X = np.clip(X, -1e6, 1e6)
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=None
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        self.scalers['main'] = scaler
        
        # ç‰¹å¾é€‰æ‹©
        selector = SelectKBest(score_func=f_regression, k=15)
        X_train_selected = selector.fit_transform(X_train_scaled, y_train)
        X_test_selected = selector.transform(X_test_scaled)
        self.feature_selector = selector
        
        # è·å–é€‰æ‹©çš„ç‰¹å¾å
        selected_indices = selector.get_support(indices=True)
        self.selected_feature_names = [self.selected_features[i] for i in selected_indices]
        
        print(f"æœ€ç»ˆé€‰æ‹©çš„ç‰¹å¾æ•°é‡: {len(self.selected_feature_names)}")
        
        models = {}
        results = {}
        
        # 1. Random Forest (åŸºç¡€æ¨¡å‹)
        print("  è®­ç»ƒ Random Forest...")
        rf_model = RandomForestRegressor(
            n_estimators=300,
            max_depth=20,
            min_samples_split=3,
            min_samples_leaf=1,
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train_selected, y_train)
        rf_pred = rf_model.predict(X_test_selected)
        
        models['random_forest'] = rf_model
        results['random_forest'] = self._evaluate_model(y_test, rf_pred)
        
        # è·å–ç‰¹å¾é‡è¦æ€§
        self.feature_importance['random_forest'] = dict(
            zip(self.selected_feature_names, rf_model.feature_importances_)
        )
        
        # 2. XGBoost (å¦‚æœå¯ç”¨)
        if XGBOOST_AVAILABLE:
            print("  è®­ç»ƒ XGBoost...")
            xgb_model = xgb.XGBRegressor(
                n_estimators=300,
                max_depth=10,
                learning_rate=0.08,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                n_jobs=-1
            )
            xgb_model.fit(X_train_selected, y_train)
            xgb_pred = xgb_model.predict(X_test_selected)
            
            models['xgboost'] = xgb_model
            results['xgboost'] = self._evaluate_model(y_test, xgb_pred)
            
            # ç‰¹å¾é‡è¦æ€§
            self.feature_importance['xgboost'] = dict(
                zip(self.selected_feature_names, xgb_model.feature_importances_)
            )
        
        # 3. LightGBM (å¦‚æœå¯ç”¨)
        if LIGHTGBM_AVAILABLE:
            print("  è®­ç»ƒ LightGBM...")
            lgb_model = lgb.LGBMRegressor(
                n_estimators=300,
                max_depth=10,
                learning_rate=0.08,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                n_jobs=-1,
                verbose=-1
            )
            lgb_model.fit(X_train_selected, y_train)
            lgb_pred = lgb_model.predict(X_test_selected)
            
            models['lightgbm'] = lgb_model
            results['lightgbm'] = self._evaluate_model(y_test, lgb_pred)
            
            # ç‰¹å¾é‡è¦æ€§
            self.feature_importance['lightgbm'] = dict(
                zip(self.selected_feature_names, lgb_model.feature_importances_)
            )
        
        # é›†æˆé¢„æµ‹
        ensemble_pred = self._ensemble_predict(models, X_test_selected)
        results['ensemble'] = self._evaluate_model(y_test, ensemble_pred)
        
        self.models = models
        self.is_trained = True
        
        # æ˜¾ç¤ºç»“æœ
        self._display_results(results)
        self._display_feature_importance()
        
        return results
    
    def _evaluate_model(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        mae = mean_absolute_error(y_true, y_pred)
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_true, y_pred)
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
        
        return {
            'MAE': mae,
            'MSE': mse,
            'RMSE': rmse,
            'R2': r2,
            'MAPE': mape
        }
    
    def _ensemble_predict(self, models: Dict, X: np.ndarray) -> np.ndarray:
        """é›†æˆé¢„æµ‹"""
        predictions = []
        weights = []
        
        if 'random_forest' in models:
            predictions.append(models['random_forest'].predict(X))
            weights.append(0.4)
        
        if 'xgboost' in models:
            predictions.append(models['xgboost'].predict(X))
            weights.append(0.35)
        
        if 'lightgbm' in models:
            predictions.append(models['lightgbm'].predict(X))
            weights.append(0.25)
        
        if len(predictions) > 1:
            weights = np.array(weights[:len(predictions)])
            weights = weights / weights.sum()
            return np.average(predictions, axis=0, weights=weights)
        else:
            return predictions[0]
    
    def _display_results(self, results: Dict):
        """æ˜¾ç¤ºè®­ç»ƒç»“æœ"""
        print("\nğŸ“Š ä¼˜åŒ–æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
        print("-" * 70)
        print(f"{'æ¨¡å‹':<15} {'MAE':<8} {'RMSE':<8} {'RÂ²':<8} {'MAPE(%)':<10}")
        print("-" * 70)
        
        for model_name, metrics in results.items():
            print(f"{model_name:<15} {metrics['MAE']:<8.3f} {metrics['RMSE']:<8.3f} "
                  f"{metrics['R2']:<8.4f} {metrics['MAPE']:<10.2f}")
        
        print("-" * 70)
    
    def _display_feature_importance(self):
        """æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§"""
        if not self.feature_importance:
            return
        
        print("\nğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ:")
        print("-" * 50)
        
        # è®¡ç®—å¹³å‡é‡è¦æ€§
        avg_importance = {}
        for feature in self.selected_feature_names:
            importances = []
            for model_name, importance_dict in self.feature_importance.items():
                if feature in importance_dict:
                    importances.append(importance_dict[feature])
            
            if importances:
                avg_importance[feature] = np.mean(importances)
        
        # æŒ‰é‡è¦æ€§æ’åº
        sorted_importance = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)
        
        print(f"{'ç‰¹å¾åç§°':<25} {'å¹³å‡é‡è¦æ€§':<12}")
        print("-" * 40)
        for feature, importance in sorted_importance[:10]:
            print(f"{feature:<25} {importance:<12.4f}")
    
    def predict_with_enhanced_features(self, ship_type: str, speed: float, 
                                     dwt: float = None, ship_age: float = None,
                                     load_condition: str = 'Laden',
                                     draft: float = None, length: float = None,
                                     latitude: float = None, longitude: float = None,
                                     heavy_fuel_cp: float = None, 
                                     light_fuel_cp: float = None,
                                     speed_cp: float = None) -> Dict:
        """
        ä½¿ç”¨å¢å¼ºç‰¹å¾è¿›è¡Œé¢„æµ‹
        
        Args:
            ship_type: èˆ¹èˆ¶ç±»å‹
            speed: èˆªè¡Œé€Ÿåº¦ (kts)
            dwt: è½½é‡å¨ (å¯é€‰)
            ship_age: èˆ¹é¾„ (å¹´) (å¯é€‰)
            load_condition: è½½é‡çŠ¶æ€ ('Laden', 'Ballast')
            draft: èˆ¹èˆ¶åƒæ°´ (m) (å¯é€‰)
            length: èˆ¹èˆ¶æ€»é•¿åº¦ (m) (å¯é€‰)
            latitude: çº¬åº¦ (å¯é€‰)
            longitude: ç»åº¦ (å¯é€‰)
            heavy_fuel_cp: é‡æ²¹CP (å¯é€‰)
            light_fuel_cp: è½»æ²¹CP (å¯é€‰)
            speed_cp: èˆªé€ŸCP (å¯é€‰)
        
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        try:
            # æ ‡å‡†åŒ–èˆ¹èˆ¶ç±»å‹
            ship_type_normalized = self._normalize_ship_type(ship_type)
            
            # æ„å»ºç‰¹å¾å‘é‡
            features = self._build_enhanced_feature_vector(
                ship_type_normalized, speed, dwt, ship_age, load_condition,
                draft, length, latitude, longitude, heavy_fuel_cp, 
                light_fuel_cp, speed_cp
            )
            
            if self.is_trained and self.models:
                # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹
                prediction = self._predict_with_trained_model(features)
                confidence = 'High'
                method = 'ml_model'
            else:
                # ä½¿ç”¨å¢å¼ºçš„åŸºäºè§„åˆ™çš„é¢„æµ‹
                prediction = self._predict_with_enhanced_rules(
                    ship_type_normalized, speed, dwt, ship_age, 
                    load_condition, draft, length
                )
                confidence = 'Medium'
                method = 'enhanced_rules'
            
            # åˆç†æ€§æ£€æŸ¥
            prediction = max(5.0, min(100.0, prediction))
            
            return {
                'predicted_consumption': round(prediction, 2),
                'confidence': confidence,
                'method': method,
                'ship_type': ship_type_normalized,
                'speed': speed,
                'input_features': {
                    'dwt': dwt,
                    'ship_age': ship_age,
                    'load_condition': load_condition,
                    'draft': draft,
                    'length': length,
                    'coordinates': (latitude, longitude) if latitude and longitude else None
                },
                'prediction_range': (
                    round(prediction * 0.9, 2),
                    round(prediction * 1.1, 2)
                ),
                'prediction_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'error': str(e),
                'ship_type': ship_type,
                'speed': speed,
                'status': 'failed'
            }
    
    def _build_enhanced_feature_vector(self, ship_type: str, speed: float,
                                     dwt: float, ship_age: float, load_condition: str,
                                     draft: float, length: float, latitude: float,
                                     longitude: float, heavy_fuel_cp: float,
                                     light_fuel_cp: float, speed_cp: float) -> np.ndarray:
        """æ„å»ºå¢å¼ºç‰¹å¾å‘é‡"""
        # è®¾ç½®é»˜è®¤å€¼
        dwt = dwt or self._estimate_dwt_from_ship_type(ship_type)
        draft = draft or self._estimate_draft_from_dwt(dwt)
        length = length or self._estimate_length_from_dwt(dwt)
        ship_age = ship_age or 10.0  # é»˜è®¤10å¹´
        latitude = latitude or 0.0
        longitude = longitude or 100.0
        heavy_fuel_cp = heavy_fuel_cp or 600.0  # é»˜è®¤é‡æ²¹ä»·æ ¼
        light_fuel_cp = light_fuel_cp or 800.0  # é»˜è®¤è½»æ²¹ä»·æ ¼
        speed_cp = speed_cp or speed  # é»˜è®¤èˆªé€ŸCPç­‰äºå®é™…èˆªé€Ÿ
        
        # æ„å»ºç‰¹å¾å­—å…¸
        feature_dict = {}
        
        # åŸºç¡€ç‰¹å¾
        feature_dict['å¹³å‡é€Ÿåº¦(kts)'] = speed
        feature_dict['èˆªè¡Œè·ç¦»(nm)'] = speed * 24  # å‡è®¾24å°æ—¶èˆªè¡Œ
        feature_dict['èˆ¹èˆ¶è½½é‡(t)'] = dwt
        feature_dict['èˆ¹èˆ¶åƒæ°´(m)'] = draft
        feature_dict['èˆ¹èˆ¶æ€»é•¿åº¦(m)'] = length
        feature_dict['èˆ¹é¾„_æ•°å€¼'] = ship_age
        feature_dict['çº¬åº¦'] = latitude
        feature_dict['ç»åº¦'] = longitude
        
        # ç§Ÿçº¦ç‰¹å¾
        feature_dict['é‡æ²¹CP_æ ‡å‡†åŒ–'] = heavy_fuel_cp
        feature_dict['è½»æ²¹CP_æ ‡å‡†åŒ–'] = light_fuel_cp
        feature_dict['èˆªé€ŸCP_æ ‡å‡†åŒ–'] = speed_cp
        
        # å·¥ç¨‹ç‰¹å¾
        feature_dict['èˆ¹èˆ¶æ•ˆç‡ç³»æ•°'] = self._get_ship_efficiency_factor(ship_type)
        feature_dict['è½½é‡çŠ¶æ€ç³»æ•°'] = self.load_condition_factors.get(load_condition, 1.0)
        feature_dict['ç»¼åˆæ•ˆç‡æŒ‡æ ‡'] = (
            feature_dict['èˆ¹èˆ¶æ•ˆç‡ç³»æ•°'] * 
            feature_dict['è½½é‡çŠ¶æ€ç³»æ•°'] * 
            speed / 10
        )
        
        # åˆ†ç±»ç‰¹å¾ç¼–ç 
        feature_dict['èˆ¹èˆ¶ç±»å‹_æ ‡å‡†åŒ–_ç¼–ç '] = self._encode_ship_type(ship_type)
        feature_dict['è½½é‡å¨ä½ç­‰çº§_ç¼–ç '] = self._encode_dwt_class(dwt)
        feature_dict['èˆ¹é¾„åˆ†ç»„_ç¼–ç '] = self._encode_age_group(ship_age)
        feature_dict['è½½é‡çŠ¶æ€_å¡«å……_ç¼–ç '] = self._encode_load_condition(load_condition)
        feature_dict['èˆªè¡ŒåŒºåŸŸ_ç¼–ç '] = self._encode_region(latitude, longitude)
        
        # è½¬æ¢ä¸ºç‰¹å¾å‘é‡
        features = []
        for feature_name in self.selected_features:
            if feature_name in feature_dict:
                features.append(feature_dict[feature_name])
            else:
                features.append(0.0)
        
        return np.array(features).reshape(1, -1)
    
    def _predict_with_trained_model(self, features: np.ndarray) -> float:
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹"""
        # æ ‡å‡†åŒ–ç‰¹å¾
        if 'main' in self.scalers:
            features_scaled = self.scalers['main'].transform(features)
        else:
            features_scaled = features
        
        # ç‰¹å¾é€‰æ‹©
        if self.feature_selector:
            features_selected = self.feature_selector.transform(features_scaled)
        else:
            features_selected = features_scaled
        
        # é›†æˆé¢„æµ‹
        predictions = []
        weights = []
        
        if 'random_forest' in self.models:
            pred = self.models['random_forest'].predict(features_selected)[0]
            predictions.append(pred)
            weights.append(0.4)
        
        if 'xgboost' in self.models:
            pred = self.models['xgboost'].predict(features_selected)[0]
            predictions.append(pred)
            weights.append(0.35)
        
        if 'lightgbm' in self.models:
            pred = self.models['lightgbm'].predict(features_selected)[0]
            predictions.append(pred)
            weights.append(0.25)
        
        if predictions:
            weights = np.array(weights[:len(predictions)])
            weights = weights / weights.sum()
            return np.average(predictions, weights=weights)
        else:
            return 25.0
    
    def _predict_with_enhanced_rules(self, ship_type: str, speed: float,
                                   dwt: float, ship_age: float,
                                   load_condition: str, draft: float,
                                   length: float) -> float:
        """ä½¿ç”¨å¢å¼ºè§„åˆ™é¢„æµ‹"""
        # åŸºç¡€æ²¹è€— (åŸºäºèˆ¹èˆ¶ç±»å‹)
        base_consumption = self.ship_type_baselines.get(ship_type, 23.0)
        
        # é€Ÿåº¦å½±å“ (éçº¿æ€§å…³ç³»)
        speed_factor = (speed / 12) ** 1.8
        
        # è½½é‡å¨å½±å“
        if dwt:
            dwt_class = self._classify_dwt(dwt)
            dwt_factor = self.dwt_class_factors.get(dwt_class, 1.0)
        else:
            dwt_factor = 1.0
        
        # èˆ¹é¾„å½±å“
        if ship_age:
            age_group = self._classify_age(ship_age)
            age_factor = self.ship_age_factors.get(age_group, 1.0)
        else:
            age_factor = 1.0
        
        # è½½é‡çŠ¶æ€å½±å“
        load_factor = self.load_condition_factors.get(load_condition, 1.0)
        
        # èˆ¹èˆ¶å°ºå¯¸å½±å“ (åŸºäºåƒæ°´å’Œé•¿åº¦)
        size_factor = 1.0
        if draft and length:
            # è¾ƒå¤§çš„èˆ¹èˆ¶é€šå¸¸æ›´é«˜æ•ˆ
            size_factor = 0.95 + (draft / 15) * 0.1 + (length / 200) * 0.05
            size_factor = min(1.15, max(0.85, size_factor))
        
        # ç»¼åˆé¢„æµ‹
        predicted_consumption = (
            base_consumption * 
            speed_factor * 
            dwt_factor * 
            age_factor * 
            load_factor * 
            size_factor
        )
        
        return predicted_consumption
    
    def _normalize_ship_type(self, ship_type: str) -> str:
        """æ ‡å‡†åŒ–èˆ¹èˆ¶ç±»å‹"""
        return self.ship_type_mapping.get(ship_type.lower(), ship_type)
    
    def _estimate_dwt_from_ship_type(self, ship_type: str) -> float:
        """æ ¹æ®èˆ¹èˆ¶ç±»å‹ä¼°ç®—è½½é‡å¨"""
        typical_dwt = {
            'Bulk Carrier': 75000,
            'Container Ship': 120000,
            'Crude Oil Tanker': 200000,
            'Chemical Tanker': 45000,
            'General Cargo': 25000,
            'Open Hatch Cargo': 35000,
            'Other': 50000
        }
        return typical_dwt.get(ship_type, 50000)
    
    def _estimate_draft_from_dwt(self, dwt: float) -> float:
        """æ ¹æ®è½½é‡å¨ä¼°ç®—åƒæ°´"""
        return 8.0 + (dwt / 100000) * 6.0  # ç»éªŒå…¬å¼
    
    def _estimate_length_from_dwt(self, dwt: float) -> float:
        """æ ¹æ®è½½é‡å¨ä¼°ç®—èˆ¹é•¿"""
        return 150.0 + (dwt / 50000) * 50.0  # ç»éªŒå…¬å¼
    
    def _get_ship_efficiency_factor(self, ship_type: str) -> float:
        """è·å–èˆ¹èˆ¶æ•ˆç‡ç³»æ•°"""
        efficiency_factors = {
            'Bulk Carrier': 1.0,
            'Container Ship': 1.15,
            'Crude Oil Tanker': 0.95,
            'Chemical Tanker': 1.05,
            'General Cargo': 1.10,
            'Open Hatch Cargo': 1.08,
            'Other': 1.12
        }
        return efficiency_factors.get(ship_type, 1.0)
    
    def _classify_dwt(self, dwt: float) -> str:
        """åˆ†ç±»è½½é‡å¨ä½"""
        if dwt < 20000:
            return 'å°å‹'
        elif dwt < 50000:
            return 'ä¸­å‹'
        elif dwt < 100000:
            return 'å¤§å‹'
        elif dwt < 200000:
            return 'è¶…å¤§å‹'
        else:
            return 'å·¨å‹'
    
    def _classify_age(self, age: float) -> str:
        """åˆ†ç±»èˆ¹é¾„"""
        if age < 5:
            return 'æ–°èˆ¹'
        elif age < 10:
            return 'ä¸­ç­‰èˆ¹é¾„'
        elif age < 20:
            return 'è€èˆ¹'
        else:
            return 'é«˜é¾„èˆ¹'
    
    def _encode_ship_type(self, ship_type: str) -> float:
        """ç¼–ç èˆ¹èˆ¶ç±»å‹"""
        type_mapping = {
            'Bulk Carrier': 0, 'Container Ship': 1, 'Crude Oil Tanker': 2,
            'Chemical Tanker': 3, 'General Cargo': 4, 'Open Hatch Cargo': 5, 'Other': 6
        }
        return type_mapping.get(ship_type, 6)
    
    def _encode_dwt_class(self, dwt: float) -> float:
        """ç¼–ç è½½é‡å¨ä½ç­‰çº§"""
        dwt_class = self._classify_dwt(dwt)
        class_mapping = {'å°å‹': 0, 'ä¸­å‹': 1, 'å¤§å‹': 2, 'è¶…å¤§å‹': 3, 'å·¨å‹': 4}
        return class_mapping.get(dwt_class, 2)
    
    def _encode_age_group(self, age: float) -> float:
        """ç¼–ç èˆ¹é¾„åˆ†ç»„"""
        age_group = self._classify_age(age)
        age_mapping = {'æ–°èˆ¹': 0, 'ä¸­ç­‰èˆ¹é¾„': 1, 'è€èˆ¹': 2, 'é«˜é¾„èˆ¹': 3}
        return age_mapping.get(age_group, 1)
    
    def _encode_load_condition(self, load_condition: str) -> float:
        """ç¼–ç è½½é‡çŠ¶æ€"""
        condition_mapping = {'Laden': 0, 'Ballast': 1, 'None': 2}
        return condition_mapping.get(load_condition, 0)
    
    def _encode_region(self, latitude: float, longitude: float) -> float:
        """ç¼–ç èˆªè¡ŒåŒºåŸŸ"""
        if latitude is None or longitude is None:
            return 0
        
        # ç®€åŒ–çš„åŒºåŸŸç¼–ç 
        if -10 <= latitude <= 30 and 30 <= longitude <= 120:
            return 2  # å°åº¦æ´‹
        elif 0 <= latitude <= 50 and 100 <= longitude <= 180:
            return 4  # è¥¿å¤ªå¹³æ´‹
        elif 30 <= latitude <= 70 and -30 <= longitude <= 50:
            return 1  # åŒ—å¤§è¥¿æ´‹
        elif -40 <= latitude <= 0 and -70 <= longitude <= 20:
            return 3  # å—å¤§è¥¿æ´‹
        else:
            return 0  # å…¶ä»–åŒºåŸŸ
    
    def save_model(self, model_dir: str = "models") -> str:
        """ä¿å­˜æ¨¡å‹"""
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_path = os.path.join(model_dir, f"enhanced_fuel_model_v3_{timestamp}.pkl")
        
        model_data = {
            'models': self.models,
            'scalers': self.scalers,
            'feature_selector': self.feature_selector,
            'selected_features': self.selected_features,
            'selected_feature_names': getattr(self, 'selected_feature_names', []),
            'feature_importance': self.feature_importance,
            'ship_type_baselines': self.ship_type_baselines,
            'load_condition_factors': self.load_condition_factors,
            'ship_age_factors': self.ship_age_factors,
            'dwt_class_factors': self.dwt_class_factors,
            'is_trained': self.is_trained,
            'version': '3.0'
        }
        
        joblib.dump(model_data, model_path)
        print(f"âœ… æ¨¡å‹V3å·²ä¿å­˜åˆ°: {model_path}")
        
        return model_path
    
    def load_model(self, model_path: str) -> bool:
        """åŠ è½½æ¨¡å‹"""
        try:
            model_data = joblib.load(model_path)
            
            self.models = model_data['models']
            self.scalers = model_data['scalers']
            self.feature_selector = model_data['feature_selector']
            self.selected_features = model_data['selected_features']
            self.selected_feature_names = model_data.get('selected_feature_names', [])
            self.feature_importance = model_data['feature_importance']
            self.ship_type_baselines = model_data.get('ship_type_baselines', self.ship_type_baselines)
            self.load_condition_factors = model_data.get('load_condition_factors', self.load_condition_factors)
            self.ship_age_factors = model_data.get('ship_age_factors', self.ship_age_factors)
            self.dwt_class_factors = model_data.get('dwt_class_factors', self.dwt_class_factors)
            self.is_trained = model_data.get('is_trained', True)
            
            print(f"âœ… æ¨¡å‹V3åŠ è½½æˆåŠŸ: {model_path}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹V3åŠ è½½å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•° - è®­ç»ƒå’Œæµ‹è¯•å¢å¼ºæ¨¡å‹V3"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆèˆ¹èˆ¶æ²¹è€—é¢„æµ‹æ¨¡å‹V3è®­ç»ƒ...")
    
    predictor = EnhancedFuelPredictorV3()
    
    try:
        # 1. åŠ è½½å’Œå‡†å¤‡æ•°æ®
        df = predictor.load_and_prepare_data("data/processed_noon_data.csv")
        
        # 2. è®­ç»ƒä¼˜åŒ–æ¨¡å‹
        results = predictor.train_optimized_model(df)
        
        # 3. ä¿å­˜æ¨¡å‹
        model_path = predictor.save_model()
        
        # 4. æµ‹è¯•å¢å¼ºé¢„æµ‹åŠŸèƒ½
        print("\nğŸ§ª æµ‹è¯•å¢å¼ºé¢„æµ‹åŠŸèƒ½...")
        
        test_cases = [
            {
                'ship_type': 'Bulk Carrier',
                'speed': 12.0,
                'dwt': 75000,
                'ship_age': 8,
                'load_condition': 'Laden',
                'draft': 12.5,
                'length': 225
            },
            {
                'ship_type': 'Container Ship',
                'speed': 18.0,
                'dwt': 120000,
                'ship_age': 5,
                'load_condition': 'Laden',
                'latitude': 35.0,
                'longitude': 139.0,
                'heavy_fuel_cp': 650
            },
            {
                'ship_type': 'Crude Oil Tanker',
                'speed': 14.0,
                'dwt': 200000,
                'ship_age': 15,
                'load_condition': 'Ballast'
            }
        ]
        
        for i, case in enumerate(test_cases, 1):
            result = predictor.predict_with_enhanced_features(**case)
            if 'predicted_consumption' in result:
                print(f"  æµ‹è¯•{i}: {case['ship_type']} @ {case['speed']}kts")
                print(f"    é¢„æµ‹æ²¹è€—: {result['predicted_consumption']}mt")
                print(f"    ç½®ä¿¡åº¦: {result['confidence']}")
                print(f"    æ–¹æ³•: {result['method']}")
                if 'input_features' in result:
                    features = result['input_features']
                    print(f"    è¾“å…¥ç‰¹å¾: DWT={features['dwt']}, èˆ¹é¾„={features['ship_age']}, "
                          f"è½½é‡çŠ¶æ€={features['load_condition']}")
        
        print(f"\nğŸ‰ å¢å¼ºæ¨¡å‹V3è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“Š æœ€ä½³æ€§èƒ½: RÂ² = {max([r['R2'] for r in results.values()]):.4f}")
        
        return predictor
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
