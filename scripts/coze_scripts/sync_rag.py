#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Coze çŸ¥è¯†åº“æ–‡ä»¶åˆ—è¡¨è·å–è„šæœ¬
æ ¹æ® Coze Open API æ–‡æ¡£è·å–çŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶åˆ—è¡¨
"""

import os
import sys
import json
import requests
from typing import Dict, List, Optional, Any
from datetime import datetime


def _print_401_hint(exc: Exception) -> None:
    """401 æ—¶æ‰“å°é‰´æƒæ’æŸ¥æç¤º"""
    res = getattr(exc, "response", None)
    if res is None or getattr(res, "status_code", None) != 401:
        return
    print("\nğŸ“Œ é‰´æƒæ’æŸ¥å»ºè®®ï¼š")
    print("  1. ç¡®è®¤ä½¿ç”¨ PATï¼ˆä¸ªäººè®¿é—®ä»¤ç‰Œï¼‰ï¼Œä¸”å·²å¼€é€š listKnowledge æƒé™")
    print("  2. åœ¨æ‰£å­æ§åˆ¶å°åˆ›å»º/æ›´æ–°ä»¤ç‰Œï¼šhttps://www.coze.cn â†’ å¼€å‘è€…è®¾ç½® â†’ API ä»¤ç‰Œ")
    print("  3. è‹¥æ¥å£è¦æ±‚ã€ŒæŒ‡å®šç©ºé—´ã€ï¼Œè®¾ç½® COZE_WORKSPACE_ID åé‡è¯•")
    print("     workspace_id ä»ç©ºé—´ URL è·å–ï¼Œå¦‚ .../space/7439012204332711970/library â†’ 7439012204332711970")


class CozeKnowledgeAPI:
    """Coze çŸ¥è¯†åº“ API å®¢æˆ·ç«¯"""
    
    BASE_URL = "https://api.coze.cn"
    
    def __init__(self, token: str, space_id: Optional[str] = None):
        """
        åˆå§‹åŒ– API å®¢æˆ·ç«¯
        
        Args:
            token: Coze API Token (PAT token)
            space_id: ç©ºé—´ IDï¼ˆå¯é€‰ï¼ŒæŸäº› API éœ€è¦ï¼‰
        """
        # ç¡®ä¿ token ä¸ä¸ºç©ºä¸”å»é™¤é¦–å°¾ç©ºæ ¼
        if not token or not token.strip():
            raise ValueError("Token ä¸èƒ½ä¸ºç©º")
        
        self.token = token.strip()
        self.space_id = space_id.strip() if space_id else None
        
        # æŒ‰ç…§ Coze API æ–‡æ¡£è¦æ±‚ï¼šAuthorization: Bearer {Access_Token}
        # æ³¨æ„ï¼šBearer åé¢å¿…é¡»æœ‰ä¸€ä¸ªç©ºæ ¼
        self.headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        
        # å¦‚æœæä¾›äº† space_idï¼Œæ·»åŠ åˆ°é»˜è®¤ headers ä¸­
        if self.space_id:
            self.headers["X-Coze-Space-Id"] = self.space_id
    
    def _get_headers(self, space_id: Optional[str] = None) -> Dict[str, str]:
        """
        è·å–è¯·æ±‚å¤´ï¼Œæ”¯æŒä¸´æ—¶è¦†ç›– space_id
        
        Args:
            space_id: ä¸´æ—¶ä½¿ç”¨çš„ç©ºé—´ IDï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è¯·æ±‚å¤´å­—å…¸
        """
        headers = self.headers.copy()
        if space_id:
            headers["X-Coze-Space-Id"] = space_id
        return headers
    
    def list_datasets(
        self,
        space_id: Optional[str] = None,
        page: int = 1,
        page_size: int = 20,
        dataset_ids: Optional[List[str]] = None,
        name: Optional[str] = None,
        status: Optional[int] = None,
        order_by: Optional[str] = None,
        order: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è·å–çŸ¥è¯†åº“ï¼ˆæ•°æ®é›†ï¼‰åˆ—è¡¨
        
        æ ¹æ® Coze API æ–‡æ¡£ï¼šhttps://www.coze.cn/open/docs/developer_guides/list_dataset
        æ¥å£åœ°å€ï¼šGET https://api.coze.cn/v1/datasets
        æƒé™è¦æ±‚ï¼šdataset:query
        
        Args:
            space_id: ç©ºé—´ IDï¼ˆå¯é€‰ï¼‰ã€‚æŸäº› API ç‰ˆæœ¬å¯èƒ½éœ€è¦æ­¤å‚æ•°
            page: é¡µç ï¼Œé»˜è®¤ 1
            page_size: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤ 20ï¼Œæœ€å¤§ 100
            dataset_ids: çŸ¥è¯†åº“ ID æ•°ç»„ï¼ˆå¯é€‰ï¼‰
            name: çŸ¥è¯†åº“åç§°ï¼ˆå¯é€‰ï¼‰ï¼Œæ”¯æŒæ¨¡ç³Šæœç´¢
            status: çŸ¥è¯†åº“çŠ¶æ€ï¼ˆå¯é€‰ï¼‰ï¼š1-æ­£å¸¸ï¼Œ2-åˆ é™¤ä¸­ï¼Œ3-å·²åˆ é™¤ï¼Œ4-è®­ç»ƒä¸­ï¼Œ5-è®­ç»ƒå¤±è´¥ï¼Œ6-ä¸Šä¼ å¤±è´¥
            order_by: æ’åºå­—æ®µï¼ˆå¯é€‰ï¼‰ã€‚å¯é€‰å€¼ï¼šcreated_at, updated_at, name
            order: æ’åºé¡ºåºï¼ˆå¯é€‰ï¼‰ã€‚å¯é€‰å€¼ï¼šasc, desc
            
        Returns:
            åŒ…å«çŸ¥è¯†åº“åˆ—è¡¨çš„å“åº”æ•°æ®
            
        Raises:
            requests.RequestException: è¯·æ±‚å¤±è´¥æ—¶æŠ›å‡º
        """
        # ä½¿ç”¨å®é™…å¯ç”¨çš„ç«¯ç‚¹ /v1/datasets
        url = f"{self.BASE_URL}/v1/datasets"
        
        # æ ¹æ®å®é™… APIï¼Œå‚æ•°åæ˜¯ page_num è€Œä¸æ˜¯ page
        params = {
            "page_num": max(page, 1),
            "page_size": min(max(page_size, 1), 100)  # é™åˆ¶åœ¨ 1~100 èŒƒå›´å†…
        }
        
        # space_id å‚æ•°ï¼ˆæŸäº› API ç‰ˆæœ¬éœ€è¦ï¼‰
        if space_id:
            params["space_id"] = space_id.strip()
        
        # å¯é€‰å‚æ•°ï¼ˆæ ¹æ®æ–‡æ¡£ï¼Œä½†å¯èƒ½æŸäº›å‚æ•°åœ¨å½“å‰ API ç‰ˆæœ¬ä¸æ”¯æŒï¼‰
        if name:
            params["name"] = name.strip()
        # æ³¨æ„ï¼šdataset_ids, status, order_by, order å¯èƒ½åœ¨æŸäº› API ç‰ˆæœ¬ä¸æ”¯æŒ
        # æš‚æ—¶ä¸æ·»åŠ ï¼Œé¿å…å‚æ•°é”™è¯¯
        
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"å“åº”å†…å®¹: {e.response.text[:500]}")
                _print_401_hint(e)
            raise
    
    def get_all_datasets(
        self,
        space_id: Optional[str] = None,
        name: Optional[str] = None,
        page_size: int = 20
    ) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰çŸ¥è¯†åº“ï¼ˆæ•°æ®é›†ï¼‰åˆ—è¡¨ï¼ˆè‡ªåŠ¨ç¿»é¡µï¼‰
        
        æ ¹æ®å®é™… APIï¼Œå“åº”æ ¼å¼ï¼š{"code": 0, "data": {"dataset_list": [...], "total": ...}}
        
        Args:
            space_id: ç©ºé—´ IDï¼ˆå¯é€‰ï¼Œä½†å»ºè®®æä¾›ï¼‰
            name: çŸ¥è¯†åº“åç§°ï¼ˆå¯é€‰ï¼‰ï¼Œæ”¯æŒæ¨¡ç³Šæœç´¢
            page_size: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤ 20ï¼Œæœ€å¤§ 100
            
        Returns:
            æ‰€æœ‰çŸ¥è¯†åº“çš„åˆ—è¡¨
        """
        all_datasets = []
        page = 1
        
        if space_id:
            print(f"ğŸ“š å¼€å§‹è·å–çŸ¥è¯†åº“åˆ—è¡¨ï¼ˆç©ºé—´ ID: {space_id}ï¼‰...")
        else:
            print(f"ğŸ“š å¼€å§‹è·å–çŸ¥è¯†åº“åˆ—è¡¨...")
        
        while True:
            try:
                result = self.list_datasets(
                    space_id=space_id,
                    page=page,
                    page_size=page_size,
                    name=name
                )
                
                # æ ¹æ®å®é™… APIï¼Œå“åº”æ ¼å¼ï¼š{"code": 0, "data": {"dataset_list": [...], "total": ...}}
                if result.get("code") != 0:
                    print(f"âŒ API è¿”å›é”™è¯¯: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                    break
                
                data = result.get("data", {})
                # å®é™… API è¿”å› dataset_list å­—æ®µ
                datasets = data.get("dataset_list") or data.get("list", [])
                total = data.get("total", len(datasets))
                has_more = data.get("has_more")
                
                all_datasets.extend(datasets)
                
                print(f"âœ… å·²è·å–ç¬¬ {page} é¡µï¼Œå…± {len(datasets)} ä¸ªçŸ¥è¯†åº“ï¼ˆæ€»è®¡: {len(all_datasets)}/{total}ï¼‰")
                
                # åˆ¤æ–­æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
                if has_more is False or len(datasets) == 0:
                    break
                elif has_more is None:
                    # å¦‚æœæ²¡æœ‰ has_more å­—æ®µï¼Œä½¿ç”¨ä¼ ç»Ÿåˆ¤æ–­æ–¹å¼
                    if len(datasets) < page_size or (total > 0 and len(all_datasets) >= total):
                        break
                
                page += 1
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ è·å–ç¬¬ {page} é¡µå¤±è´¥: {str(e)}")
                break
        
        print(f"âœ… å®Œæˆï¼å…±è·å– {len(all_datasets)} ä¸ªçŸ¥è¯†åº“")
        return all_datasets
    
    def list_knowledge_files(
        self, 
        dataset_id: str,
        space_id: Optional[str] = None,
        page: int = 1,
        size: int = 10
    ) -> Dict[str, Any]:
        """
        è·å–çŸ¥è¯†åº“æ–‡ä»¶åˆ—è¡¨
        
        æ ¹æ® Coze API æ–‡æ¡£ï¼šhttps://www.coze.cn/open/docs/developer_guides/list_knowledge_files
        æ¥å£åœ°å€ï¼šPOST https://api.coze.cn/open_api/knowledge/document/list
        æƒé™è¦æ±‚ï¼šlistDocument
        
        Args:
            dataset_id: çŸ¥è¯†åº“ IDï¼ˆå¿…é€‰ï¼‰ï¼Œå³ knowledge URL ä¸­ knowledge åçš„æ•°å­—
            space_id: ç©ºé—´ IDï¼ˆå¯é€‰ï¼‰ï¼Œå³ space URL ä¸­ space åçš„æ•°å­—
            page: åˆ†é¡µé¡µç ï¼Œé»˜è®¤ 1ï¼Œä»ç¬¬ä¸€é¡µå¼€å§‹
            size: æ¯é¡µè¿”å›çš„æ•°æ®é‡ï¼Œé»˜è®¤ 10
            
        Returns:
            åŒ…å«æ–‡ä»¶åˆ—è¡¨çš„å“åº”æ•°æ®ï¼Œæ ¼å¼ï¼š{"code": 0, "msg": "success", "document_infos": [...], "total": ...}
            
        Raises:
            requests.RequestException: è¯·æ±‚å¤±è´¥æ—¶æŠ›å‡º
        """
        url = f"{self.BASE_URL}/open_api/knowledge/document/list"
        
        current_space_id = space_id or self.space_id
        if not current_space_id:
            raise ValueError("space_id æ˜¯å¿…éœ€çš„ï¼Œè¯·åœ¨åˆå§‹åŒ–æ—¶æä¾›æˆ–åœ¨æ­¤æ–¹æ³•ä¸­æŒ‡å®š")
        
        headers = self._get_headers(current_space_id)
        # æ–‡æ¡£è¦æ±‚ï¼šAgw-Js-Conv é˜²æ­¢ä¸¢å¤±æ•°å­—ç±»å‹å‚æ•°çš„ç²¾åº¦
        headers["Agw-Js-Conv"] = "1"
        
        # è¯·æ±‚ä½“ï¼šdataset_id å¿…é€‰ï¼Œpage/size å¯é€‰
        data = {
            "dataset_id": str(dataset_id).strip(),
            "page": max(1, int(page)),
            "size": max(1, min(int(size), 100))
        }
        
        try:
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code != 200:
                body = response.text
                if body.strip():
                    try:
                        err = response.json()
                        body = json.dumps(err, ensure_ascii=False, indent=2)
                    except Exception:
                        pass
                print(f"âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                print(f"å“åº”: {body[:800]}")
                response.raise_for_status()
            
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
            if hasattr(e, "response") and e.response is not None:
                _print_401_hint(e)
            raise
    
    def get_all_knowledge_files(
        self, 
        dataset_id: str,
        space_id: Optional[str] = None,
        page_size: int = 10
    ) -> List[Dict[str, Any]]:
        """
        è·å–çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆè‡ªåŠ¨ç¿»é¡µï¼‰
        
        æ ¹æ® API æ–‡æ¡£ï¼Œå“åº”æ ¼å¼ï¼š{"code": 0, "msg": "success", "document_infos": [...], "total": ...}
        
        Args:
            dataset_id: çŸ¥è¯†åº“ ID
            space_id: ç©ºé—´ IDï¼ˆå¯é€‰ï¼Œå¦‚æœåˆå§‹åŒ–æ—¶æœªæä¾›ï¼Œå¯åœ¨æ­¤å¤„æŒ‡å®šï¼‰
            page_size: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤ 10
            
        Returns:
            æ‰€æœ‰æ–‡ä»¶çš„åˆ—è¡¨
        """
        all_files = []
        page = 1  # æ–‡æ¡£é»˜è®¤ä»ç¬¬ä¸€é¡µå¼€å§‹
        
        print(f"ğŸ“š å¼€å§‹è·å–çŸ¥è¯†åº“ {dataset_id} çš„æ–‡ä»¶åˆ—è¡¨...")
        
        while True:
            try:
                result = self.list_knowledge_files(
                    dataset_id=dataset_id,
                    space_id=space_id,
                    page=page,
                    size=page_size
                )
                
                if result.get("code") != 0:
                    print(f"âŒ API è¿”å›é”™è¯¯: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                    break
                
                document_infos = result.get("document_infos", [])
                total = result.get("total", len(document_infos))
                
                all_files.extend(document_infos)
                
                print(f"âœ… å·²è·å–ç¬¬ {page} é¡µï¼Œå…± {len(document_infos)} ä¸ªæ–‡ä»¶ï¼ˆæ€»è®¡: {len(all_files)}/{total}ï¼‰")
                
                if len(document_infos) < page_size or (total > 0 and len(all_files) >= total):
                    break
                
                page += 1
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ è·å–ç¬¬ {page} é¡µå¤±è´¥: {str(e)}")
                break
        
        print(f"âœ… å®Œæˆï¼å…±è·å– {len(all_files)} ä¸ªæ–‡ä»¶")
        return all_files
    
    def get_file_detail(self, file_id: str, knowledge_id: str) -> Dict[str, Any]:
        """
        è·å–æ–‡ä»¶è¯¦æƒ…
        
        Args:
            file_id: æ–‡ä»¶ ID
            knowledge_id: çŸ¥è¯†åº“ ID
            
        Returns:
            æ–‡ä»¶è¯¦æƒ…æ•°æ®
        """
        url = f"{self.BASE_URL}/open_api/v2/knowledge/files/{file_id}"
        
        params = {
            "knowledge_id": knowledge_id
        }
        
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ è·å–æ–‡ä»¶è¯¦æƒ…å¤±è´¥: {str(e)}")
            if hasattr(e.response, 'text'):
                print(f"å“åº”å†…å®¹: {e.response.text}")
            raise


def format_timestamp(timestamp: Any) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼"""
    if timestamp is None:
        return "N/A"
    try:
        if isinstance(timestamp, (int, float)):
            from datetime import datetime
            return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
        elif isinstance(timestamp, str):
            # å¤„ç† ISO æ ¼å¼å­—ç¬¦ä¸²
            from datetime import datetime
            try:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                return dt.strftime("%Y-%m-%d %H:%M:%S")
            except (ValueError, AttributeError):
                return timestamp
        return str(timestamp)
    except (ValueError, OSError, OverflowError):
        return str(timestamp)


def print_datasets_summary(datasets: List[Dict[str, Any]]):
    """
    æ‰“å°çŸ¥è¯†åº“åˆ—è¡¨æ‘˜è¦
    
    Args:
        datasets: çŸ¥è¯†åº“åˆ—è¡¨
    """
    if not datasets:
        print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°çŸ¥è¯†åº“")
        return
    
    print(f"\n{'='*80}")
    print(f"ğŸ“š çŸ¥è¯†åº“åˆ—è¡¨æ‘˜è¦ï¼ˆå…± {len(datasets)} ä¸ªçŸ¥è¯†åº“ï¼‰")
    print(f"{'='*80}\n")
    
    for idx, dataset_info in enumerate(datasets, 1):
        # æ ¹æ®å®é™… API è¿”å›ï¼Œå­—æ®µåæ˜¯ dataset_id
        dataset_id = dataset_info.get("dataset_id") or dataset_info.get("id") or "N/A"
        dataset_name = dataset_info.get("name") or "N/A"
        description = dataset_info.get("description") or ""
        
        # çŠ¶æ€ä¿¡æ¯ï¼ˆ1-æ­£å¸¸ï¼Œ2-åˆ é™¤ä¸­ï¼Œ3-å·²åˆ é™¤ï¼Œ4-è®­ç»ƒä¸­ï¼Œ5-è®­ç»ƒå¤±è´¥ï¼Œ6-ä¸Šä¼ å¤±è´¥ï¼‰
        status = dataset_info.get("status", "N/A")
        status_map = {1: "æ­£å¸¸", 2: "åˆ é™¤ä¸­", 3: "å·²åˆ é™¤", 4: "è®­ç»ƒä¸­", 5: "è®­ç»ƒå¤±è´¥", 6: "ä¸Šä¼ å¤±è´¥"}
        status_str = status_map.get(status, f"æœªçŸ¥({status})") if isinstance(status, int) else str(status)
        
        # æ–‡ä»¶ä¿¡æ¯
        file_list = dataset_info.get("file_list", [])
        file_count = len(file_list) if isinstance(file_list, list) else 0
        
        # å¤§å°ä¿¡æ¯ï¼ˆå®é™… API è¿”å› all_file_size å­—ç¬¦ä¸²ï¼‰
        all_file_size = dataset_info.get("all_file_size")
        if all_file_size:
            try:
                size_bytes = int(all_file_size)
                if size_bytes < 1024:
                    size_str = f"{size_bytes} B"
                elif size_bytes < 1024 * 1024:
                    size_str = f"{size_bytes / 1024:.2f} KB"
                elif size_bytes < 1024 * 1024 * 1024:
                    size_str = f"{size_bytes / (1024 * 1024):.2f} MB"
                else:
                    size_str = f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"
            except (ValueError, TypeError):
                size_str = str(all_file_size)
        else:
            size_str = "N/A"
        
        # ç»Ÿè®¡ä¿¡æ¯
        slice_count = dataset_info.get("slice_count", 0)
        hit_count = dataset_info.get("hit_count", 0)
        doc_count = dataset_info.get("doc_count", 0)
        format_type = dataset_info.get("format_type", "N/A")
        creator_name = dataset_info.get("creator_name", "")
        
        # æ—¶é—´ä¿¡æ¯ï¼ˆå®é™… API è¿”å› Unix æ—¶é—´æˆ³ï¼‰
        created_at = format_timestamp(dataset_info.get("create_time") or dataset_info.get("created_at"))
        updated_at = format_timestamp(dataset_info.get("update_time") or dataset_info.get("updated_at"))
        
        print(f"{idx}. {dataset_name}")
        print(f"   ID: {dataset_id}")
        print(f"   çŠ¶æ€: {status_str}")
        print(f"   ç±»å‹: {format_type}")
        print(f"   æ–‡ä»¶æ•°: {file_count}")
        if file_list and len(file_list) > 0:
            print(f"   æ–‡ä»¶åˆ—è¡¨: {', '.join(file_list[:5])}{' ...' if len(file_list) > 5 else ''}")
        print(f"   æ€»å¤§å°: {size_str}")
        print(f"   åˆ†æ®µæ•°: {slice_count}")
        print(f"   æ–‡æ¡£æ•°: {doc_count}")
        print(f"   å‘½ä¸­æ•°: {hit_count}")
        if creator_name:
            print(f"   åˆ›å»ºè€…: {creator_name}")
        if description:
            print(f"   æè¿°: {description[:100]}{'...' if len(description) > 100 else ''}")
        print(f"   åˆ›å»ºæ—¶é—´: {created_at}")
        print(f"   æ›´æ–°æ—¶é—´: {updated_at}")
        print()


def print_files_summary(files: List[Dict[str, Any]]):
    """
    æ‰“å°æ–‡ä»¶åˆ—è¡¨æ‘˜è¦
    
    æ ¹æ® API æ–‡æ¡£ï¼ŒDocumentInfo å¯¹è±¡åŒ…å«ï¼šdocument_id, name, type, size, status, format_type ç­‰å­—æ®µ
    
    Args:
        files: æ–‡ä»¶åˆ—è¡¨ï¼ˆDocumentInfo å¯¹è±¡æ•°ç»„ï¼‰
    """
    if not files:
        print("ğŸ“ çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ–‡ä»¶")
        return
    
    print(f"\n{'='*80}")
    print(f"ğŸ“‹ æ–‡ä»¶åˆ—è¡¨æ‘˜è¦ï¼ˆå…± {len(files)} ä¸ªæ–‡ä»¶ï¼‰")
    print(f"{'='*80}\n")
    
    for idx, file_info in enumerate(files, 1):
        # æ ¹æ® API æ–‡æ¡£ï¼Œå­—æ®µåæ˜¯ document_id
        document_id = file_info.get("document_id") or file_info.get("id") or "N/A"
        file_name = file_info.get("name") or "N/A"
        file_type = file_info.get("type") or "N/A"
        
        # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        size = file_info.get("size", 0)
        if size:
            try:
                size_bytes = int(size)
                if size_bytes < 1024:
                    size_str = f"{size_bytes} B"
                elif size_bytes < 1024 * 1024:
                    size_str = f"{size_bytes / 1024:.2f} KB"
                elif size_bytes < 1024 * 1024 * 1024:
                    size_str = f"{size_bytes / (1024 * 1024):.2f} MB"
                else:
                    size_str = f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"
            except (ValueError, TypeError):
                size_str = str(size)
        else:
            size_str = "N/A"
        
        # çŠ¶æ€ä¿¡æ¯ï¼ˆ0: å¾…å¤„ç†, 1: å¤„ç†å®Œæ¯•, 2: å¤„ç†å¤±è´¥ï¼‰
        status = file_info.get("status", "N/A")
        status_map = {0: "å¾…å¤„ç†", 1: "å¤„ç†å®Œæ¯•", 2: "å¤„ç†å¤±è´¥"}
        status_str = status_map.get(status, f"æœªçŸ¥({status})") if isinstance(status, int) else str(status)
        
        # æ ¼å¼ç±»å‹ï¼ˆ0: è¡¨æ ¼, 1: ç½‘é¡µ, 2: å›¾ç‰‡, 3: txt/pdf/docxï¼‰
        format_type = file_info.get("format_type", "N/A")
        format_map = {0: "è¡¨æ ¼", 1: "ç½‘é¡µ", 2: "å›¾ç‰‡", 3: "æ–‡æ¡£"}
        format_str = format_map.get(format_type, f"æœªçŸ¥({format_type})") if isinstance(format_type, int) else str(format_type)
        
        # ä¸Šä¼ æ–¹å¼ï¼ˆ0: ä¸Šä¼ æ–‡ä»¶, 1: ä¸Šä¼ åœ¨çº¿é“¾æ¥ï¼‰
        source_type = file_info.get("source_type", "N/A")
        source_map = {0: "ä¸Šä¼ æ–‡ä»¶", 1: "ä¸Šä¼ åœ¨çº¿é“¾æ¥"}
        source_str = source_map.get(source_type, f"æœªçŸ¥({source_type})") if isinstance(source_type, int) else str(source_type)
        
        # ç»Ÿè®¡ä¿¡æ¯
        slice_count = file_info.get("slice_count", 0)
        hit_count = file_info.get("hit_count", 0)
        chat_count = file_info.get("chat_count", 0)
        
        # æ—¶é—´ä¿¡æ¯ï¼ˆUnix æ—¶é—´æˆ³ï¼‰
        created_at = format_timestamp(file_info.get("create_time") or file_info.get("created_at"))
        updated_at = format_timestamp(file_info.get("update_time") or file_info.get("updated_at"))
        
        print(f"{idx}. {file_name}")
        print(f"   ID: {document_id}")
        print(f"   ç±»å‹: {file_type} ({format_str})")
        print(f"   å¤§å°: {size_str}")
        print(f"   çŠ¶æ€: {status_str}")
        print(f"   ä¸Šä¼ æ–¹å¼: {source_str}")
        print(f"   åˆ†æ®µæ•°: {slice_count}")
        print(f"   å‘½ä¸­æ•°: {hit_count}")
        if chat_count:
            print(f"   å­—æ•°: {chat_count}")
        print(f"   åˆ›å»ºæ—¶é—´: {created_at}")
        print(f"   æ›´æ–°æ—¶é—´: {updated_at}")
        print()


def save_datasets_to_json(datasets: List[Dict[str, Any]], output_path: str = "knowledge_datasets.json"):
    """
    å°†çŸ¥è¯†åº“åˆ—è¡¨ä¿å­˜åˆ° JSON æ–‡ä»¶
    
    Args:
        datasets: çŸ¥è¯†åº“åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    output_data = {
        "export_time": datetime.now().isoformat(),
        "total": len(datasets),
        "datasets": datasets
    }
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ çŸ¥è¯†åº“åˆ—è¡¨å·²ä¿å­˜åˆ°: {output_path}")


def save_files_to_json(files: List[Dict[str, Any]], output_path: str = "knowledge_files.json"):
    """
    å°†æ–‡ä»¶åˆ—è¡¨ä¿å­˜åˆ° JSON æ–‡ä»¶
    
    Args:
        files: æ–‡ä»¶åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    output_data = {
        "export_time": datetime.now().isoformat(),
        "total": len(files),
        "files": files
    }
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ æ–‡ä»¶åˆ—è¡¨å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼è·å–é…ç½®ï¼Œå¹¶å»é™¤é¦–å°¾ç©ºæ ¼å’Œæ¢è¡Œç¬¦
    token_raw = os.getenv("COZE_TOKEN") or os.getenv("COZE_API_TOKEN") or "pat_ESpGyZR84pzIr8AMLhdpMbeFYxpZndnLNdOOaDpEvuVnD6ctWEh1yg6d71JnzOLl"
    token = token_raw.strip().replace('\n', '').replace('\r', '') if token_raw else None
    
    knowledge_id = (os.getenv("COZE_KNOWLEDGE_ID") or "7598823790127366163").strip()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    # æ”¯æŒçš„æ¨¡å¼ï¼š
    # 1. python sync_rag.py list - åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†åº“
    # 2. python sync_rag.py files [knowledge_id] - åˆ—å‡ºæŒ‡å®šçŸ¥è¯†åº“çš„æ–‡ä»¶
    # 3. python sync_rag.py <token> [knowledge_id] - å…¼å®¹æ—§ç‰ˆæœ¬ç”¨æ³•
    
    mode = "files"  # é»˜è®¤æ¨¡å¼ï¼šæŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨
    if len(sys.argv) > 1:
        first_arg = sys.argv[1].lower()
        if first_arg in ["list", "datasets", "knowledge"]:
            mode = "list"
        elif first_arg in ["files", "file"]:
            mode = "files"
            if len(sys.argv) > 2:
                knowledge_id = sys.argv[2].strip()
        elif first_arg.startswith("sk-") or first_arg.startswith("pat_"):
            # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ token
            token = sys.argv[1].strip()
            if len(sys.argv) > 2:
                knowledge_id = sys.argv[2].strip()
        else:
            # å¦‚æœç¬¬ä¸€ä¸ªå‚æ•°ä¸æ˜¯æ¨¡å¼ï¼Œå¯èƒ½æ˜¯ knowledge_id
            knowledge_id = sys.argv[1].strip()
    
    # æ£€æŸ¥å¿…è¦çš„å‚æ•°
    if not token:
        print("âŒ é”™è¯¯: æœªæä¾› Coze API Token")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  æŸ¥çœ‹çŸ¥è¯†åº“åˆ—è¡¨:")
        print("    python sync_rag.py list")
        print("  æŸ¥çœ‹çŸ¥è¯†åº“æ–‡ä»¶:")
        print("    python sync_rag.py files [knowledge_id]")
        print("  æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡:")
        print("    export COZE_TOKEN='your_token'")
        print("    export COZE_KNOWLEDGE_ID='your_knowledge_id'")
        sys.exit(1)
    
    # è·å– space_idï¼ˆæŸäº› API éœ€è¦ï¼‰
    space_id = (os.getenv("COZE_WORKSPACE_ID") or "7487472502496231460").strip() or None
    
    # åˆ›å»º API å®¢æˆ·ç«¯
    api = CozeKnowledgeAPI(token=token, space_id=space_id)
    
    try:
        if mode == "list":
            # åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†åº“
            print("=" * 80)
            print("ğŸ“š è·å–çŸ¥è¯†åº“åˆ—è¡¨")
            print("=" * 80)
            
            # æ ¹æ®å®é™… APIï¼Œå¯èƒ½éœ€è¦ space_id å‚æ•°ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
            space_id = (os.getenv("COZE_WORKSPACE_ID") or "7487472502496231460").strip() or None
            if space_id:
                print(f"   ä½¿ç”¨ç©ºé—´ ID: {space_id}")
            
            datasets = api.get_all_datasets(space_id=space_id)
            
            # æ‰“å°æ‘˜è¦
            print_datasets_summary(datasets)
            
            # ä¿å­˜åˆ° JSON æ–‡ä»¶
            output_file = f"knowledge_datasets_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            save_datasets_to_json(datasets, output_file)
            
            return datasets
            
        else:
            # æŸ¥çœ‹æŒ‡å®šçŸ¥è¯†åº“çš„æ–‡ä»¶åˆ—è¡¨
            if not knowledge_id:
                print("âŒ é”™è¯¯: æœªæä¾›çŸ¥è¯†åº“ ID")
                print("\nä½¿ç”¨æ–¹æ³•:")
                print("  python sync_rag.py files <knowledge_id>")
                print("  æˆ–è®¾ç½®ç¯å¢ƒå˜é‡: export COZE_KNOWLEDGE_ID='your_knowledge_id'")
                sys.exit(1)
            
            print("=" * 80)
            print(f"ğŸ“‹ è·å–çŸ¥è¯†åº“ {knowledge_id} çš„æ–‡ä»¶åˆ—è¡¨")
            print("=" * 80)
            
            # è·å– space_idï¼ˆæ–‡ä»¶åˆ—è¡¨ API éœ€è¦ï¼‰
            space_id = (os.getenv("COZE_WORKSPACE_ID") or "7487472502496231460").strip() or None
            if space_id:
                print(f"   ä½¿ç”¨ç©ºé—´ ID: {space_id}")
            
            files = api.get_all_knowledge_files(dataset_id=knowledge_id, space_id=space_id)
            
            # æ‰“å°æ‘˜è¦
            print_files_summary(files)
            
            # ä¿å­˜åˆ° JSON æ–‡ä»¶
            output_file = f"knowledge_files_{knowledge_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            save_files_to_json(files, output_file)
            
            return files
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
